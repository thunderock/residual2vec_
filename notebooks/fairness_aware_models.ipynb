{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/ashutosh/miniconda3/envs/study/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "2022-08-11 01:19:03.030823: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2022-08-11 01:19:03.055755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "2022-08-11 01:19:03.056838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e849881650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-11 01:19:03.056852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-11 01:19:03.057162: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import graph_tool.all as gt\n",
    "import graph_embeddings\n",
    "from models.crosswalk import Crosswalk\n",
    "from utils.score import statistical_parity\n",
    "import faiss\n",
    "import residual2vec as rv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DATA_FILE = '../data/polbooks.gml'\n",
    "G = nx.read_gml(DATA_FILE)\n",
    "G = nx.relabel.convert_node_labels_to_integers(G, first_label=0, ordering='default')\n",
    "\n",
    "nodes = G.nodes(data=True)\n",
    "labels, group_ids = np.unique([n[1]['value'] for n in nodes], return_inverse=True)\n",
    "\n",
    "A = nx.adjacency_matrix(G).asfptype()\n",
    "deg = np.array(A.sum(axis=1)).reshape(-1)\n",
    "G = nx.from_scipy_sparse_matrix(A)\n",
    "\n",
    "models = {}\n",
    "window_length = 5\n",
    "num_walks = 10\n",
    "dim = 128\n",
    "\n",
    "models[\"baseline\"] = graph_embeddings.DeepWalk(window_length=window_length, num_walks=num_walks, restart_prob=0)\n",
    "\n",
    "models[\"degree-unbiased\"] = rv.residual2vec_sgd(\n",
    "    noise_sampler=rv.ConfigModelNodeSampler(),\n",
    "    window_length=window_length,\n",
    "    num_walks=num_walks,\n",
    "    cuda=True,\n",
    "    walk_length=80\n",
    ")\n",
    "\n",
    "models[\"group-unbiased\"] = rv.residual2vec_sgd(\n",
    "    noise_sampler=rv.SBMNodeSampler(\n",
    "        group_membership=group_ids, window_length=window_length,\n",
    "    ),\n",
    "    window_length=window_length,\n",
    "    num_walks=num_walks,\n",
    "    cuda=True,\n",
    "    walk_length=80,\n",
    ")\n",
    "\n",
    "models[\"fairwalk\"] = graph_embeddings.Fairwalk(window_length=window_length, num_walks=num_walks)\n",
    "models[\"fairwalk-group\"] = graph_embeddings.Fairwalk(\n",
    "    window_length=window_length, num_walks=num_walks, group_membership=group_ids\n",
    ")\n",
    "models['GCN'] = graph_embeddings.GCN()\n",
    "models[\"gcn-doubleK\"] = graph_embeddings.GCN(num_default_features=dim * 2)\n",
    "models[\"graphsage\"] = graph_embeddings.GraphSage()\n",
    "models[\"graphsage-doubleK\"] = graph_embeddings.GraphSage(num_default_features=dim * 2)\n",
    "models[\"gat\"] = graph_embeddings.GAT(layer_sizes=[64, 256])\n",
    "models[\"gat-doubleK\"] = graph_embeddings.GAT(num_default_features=dim * 2)\n",
    "\n",
    "models['crosswalk'] = Crosswalk(group_membership=group_ids, window_length=window_length, num_walks=num_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0., 1., 1., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 1., 0.]]),\n",
       " (105, 105))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0:].todense(), A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████████▏                                                                                                               | 1/12 [00:00<00:01,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk\n",
      "residual2vec_sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                 | 0/329 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.25]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.2]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.22]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.24]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.2]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.15]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.18]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.24]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.12]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.16]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.21]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.15]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.21]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.16]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.18]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.13]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.27]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.22]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.25]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.18]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.21]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.12]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.1]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.15]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.15]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.1]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.15]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.16]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.12]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.14]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.2]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.17]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.19]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.05]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.18]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.19]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.17]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.17]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.14]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.14]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.21]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.17]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.17]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.19]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.18]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.12]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.14]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.19]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.12]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.12]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.14]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 313.69it/s, loss=1.1]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.15]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 313.69it/s, loss=1.1]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.12]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.06]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.05]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.03]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.03]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.12]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.03]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.06]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 313.69it/s, loss=1.1]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.06]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.03]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.13]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.09]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.06]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.16]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.05]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.14]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 313.69it/s, loss=1.1]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.06]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.08]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.11]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 313.69it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.13]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.12]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.08]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.16]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.08]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.991]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.995]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.996]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.08]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.986]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.06]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.979]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.992]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.1]\u001B[A\n",
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.999]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.991]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|██████████████████████████████████████████████████████████████████▊                                           | 200/329 [00:00<00:00, 348.66it/s, loss=1]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.08]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.07]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.988]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.09]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.955]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.987]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.982]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.959]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.05]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.03]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.08]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.02]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.04]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████▍                                         | 200/329 [00:00<00:00, 348.66it/s, loss=0.999]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 348.66it/s, loss=1.01]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.01]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.973]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.08]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.924]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.998]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.06]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.979]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.08]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.06]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.03]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.01]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.07]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.946]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.03]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.01]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.02]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.05]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.949]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.01]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.978]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.08]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.04]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.08]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.02]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 300/329 [00:00<00:00, 365.54it/s, loss=1]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.05]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.06]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 365.54it/s, loss=1.03]\u001B[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 300/329 [00:00<00:00, 365.54it/s, loss=0.973]\u001B[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:00<00:00, 330.76it/s, loss=0.992]\u001B[A\n",
      " 17%|████████████████████▎                                                                                                     | 2/12 [00:04<00:28,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual2vec_sgd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                 | 0/329 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.39]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.38]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.37]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.36]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.35]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.34]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.31]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.27]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.33]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.29]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.26]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.26]\u001B[A\n",
      "  0%|                                                                                                                       | 0/329 [00:00<?, ?it/s, loss=1.3]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.32]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.27]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.28]\u001B[A\n",
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.23]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/329 [00:00<?, ?it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.32]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.32]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.23]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.22]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.31]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.22]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.23]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.23]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.23]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.21]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.22]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.28]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.29]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.22]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.25]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.26]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.27]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.24]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████▊                                                                           | 100/329 [00:00<00:00, 328.36it/s, loss=1.3]\u001B[A\n",
      " 30%|████████████████████████████████▌                                                                          | 100/329 [00:00<00:00, 328.36it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.3]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.3]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.28]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.31]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.29]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.3]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.29]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.28]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████▋                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.2]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.29]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.29]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.19]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.29]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.28]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.28]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.17]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.23]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.27]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.24]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.19]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.19]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.21]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.25]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.22]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 61%|█████████████████████████████████████████████████████████████████                                          | 200/329 [00:00<00:00, 355.32it/s, loss=1.26]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.26]\u001B[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████▍         | 300/329 [00:00<00:00, 366.27it/s, loss=1.2]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.24]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.18]\u001B[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████▍         | 300/329 [00:00<00:00, 366.27it/s, loss=1.2]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.22]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.23]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.24]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.22]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.19]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.27]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.24]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.22]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.23]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.22]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.29]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████▍         | 300/329 [00:00<00:00, 366.27it/s, loss=1.2]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████▍         | 300/329 [00:00<00:00, 366.27it/s, loss=1.2]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.24]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.23]\u001B[A\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████▍         | 300/329 [00:00<00:00, 366.27it/s, loss=1.3]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.22]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.23]\u001B[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████▌         | 300/329 [00:00<00:00, 366.27it/s, loss=1.25]\u001B[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 329/329 [00:00<00:00, 335.18it/s, loss=1.28]\u001B[A\n",
      " 25%|██████████████████████████████▌                                                                                           | 3/12 [00:05<00:18,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairwalk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████████████████▋                                                                                 | 4/12 [00:06<00:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairwalk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████████████████████▊                                                                       | 5/12 [00:06<00:06,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN\n",
      "Using GCN (local pooling) filters...\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe70426d4d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe70426d4d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe81194f450>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe81194f450>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe7042f6150>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe7042f6150>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe70433b990>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe70433b990>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0078 - val_loss: 0.0110\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - val_loss: 0.0111\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0077 - val_loss: 0.0112\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0078 - val_loss: 0.0113\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0079 - val_loss: 0.0112\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - val_loss: 0.0113\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - val_loss: 0.0112\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - val_loss: 0.0112\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0072 - val_loss: 0.0111\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0073 - val_loss: 0.0112\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0074 - val_loss: 0.0112\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - val_loss: 0.0112\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0073 - val_loss: 0.0113\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0074 - val_loss: 0.0113\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - val_loss: 0.0115\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - val_loss: 0.0114\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0070 - val_loss: 0.0113\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - val_loss: 0.0112\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - val_loss: 0.0113\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - val_loss: 0.0114\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066 - val_loss: 0.0120\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - val_loss: 0.0118\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0070 - val_loss: 0.0118\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - val_loss: 0.0118\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - val_loss: 0.0118\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - val_loss: 0.0120\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - val_loss: 0.0121\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.0121\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0062 - val_loss: 0.0119\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0062 - val_loss: 0.0118\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - val_loss: 0.0118\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - val_loss: 0.0118\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0058 - val_loss: 0.0119\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - val_loss: 0.0121\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - val_loss: 0.0124\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - val_loss: 0.0124\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0062 - val_loss: 0.0124\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - val_loss: 0.0124\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0056 - val_loss: 0.0124\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - val_loss: 0.0125\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0056 - val_loss: 0.0125\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0059 - val_loss: 0.0128\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - val_loss: 0.0131\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0055 - val_loss: 0.0134\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0061 - val_loss: 0.0132\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0055 - val_loss: 0.0132\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - val_loss: 0.0134\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0057 - val_loss: 0.0133\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - val_loss: 0.0132\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0062 - val_loss: 0.0130\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - val_loss: 0.0130\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0054 - val_loss: 0.0130\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0055 - val_loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████████████████                                                             | 6/12 [00:13<00:18,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN\n",
      "Using GCN (local pooling) filters...\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe6f427d550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe6f427d550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe6f42bda50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe6f42bda50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe6f427a090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphConvolution.call of <stellargraph.layer.gcn.GraphConvolution object at 0x7fe6f427a090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe6f4304e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe6f4304e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0080 - val_loss: 0.0109\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0078 - val_loss: 0.0111\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - val_loss: 0.0113\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0076 - val_loss: 0.0115\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0077 - val_loss: 0.0116\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0075 - val_loss: 0.0116\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - val_loss: 0.0116\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - val_loss: 0.0117\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - val_loss: 0.0121\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0074 - val_loss: 0.0122\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - val_loss: 0.0121\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0071 - val_loss: 0.0120\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0072 - val_loss: 0.0120\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - val_loss: 0.0119\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0070 - val_loss: 0.0119\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - val_loss: 0.0118\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0070 - val_loss: 0.0113\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - val_loss: 0.0114\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - val_loss: 0.0115\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - val_loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - val_loss: 0.0118\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - val_loss: 0.0118\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0066 - val_loss: 0.0119\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066 - val_loss: 0.0121\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - val_loss: 0.0121\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0067 - val_loss: 0.0122\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - val_loss: 0.0124\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - val_loss: 0.0128\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - val_loss: 0.0130\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0061 - val_loss: 0.0128\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - val_loss: 0.0123\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - val_loss: 0.0122\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - val_loss: 0.0121\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - val_loss: 0.0120\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - val_loss: 0.0121\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - val_loss: 0.0122\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0062 - val_loss: 0.0124\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - val_loss: 0.0126\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0058 - val_loss: 0.0125\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - val_loss: 0.0124\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0061 - val_loss: 0.0124\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - val_loss: 0.0128\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0060 - val_loss: 0.0127\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - val_loss: 0.0123\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - val_loss: 0.0122\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0057 - val_loss: 0.0122\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.0122\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - val_loss: 0.0122\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0057 - val_loss: 0.0122\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0054 - val_loss: 0.0121\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0053 - val_loss: 0.0121\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - val_loss: 0.0121\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - val_loss: 0.0120\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - val_loss: 0.0120\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - val_loss: 0.0121\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - val_loss: 0.0122\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - val_loss: 0.0123\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - val_loss: 0.0124\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - val_loss: 0.0125\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0053 - val_loss: 0.0126\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - val_loss: 0.0128\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - val_loss: 0.0129\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0051 - val_loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████████████████████████████▏                                                  | 7/12 [00:21<00:23,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSage\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7117983d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7117983d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe711798e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7117983d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7117983d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LinkEmbedding.call of <stellargraph.layer.link_inference.LinkEmbedding object at 0x7fe7c3bbcf50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method LinkEmbedding.call of <stellargraph.layer.link_inference.LinkEmbedding object at 0x7fe7c3bbcf50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7146 - binary_accuracy: 0.5000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:27.041291: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 651ms/step - loss: 0.7022 - binary_accuracy: 0.5000\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:27.709815: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 565ms/step - loss: 0.6783 - binary_accuracy: 0.5286\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:28.379570: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 700ms/step - loss: 0.6515 - binary_accuracy: 0.6286\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:29.079747: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 771ms/step - loss: 0.6327 - binary_accuracy: 0.6619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:29.750111: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:30.315981: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\r",
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 8/12 [00:26<00:19,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSage\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe6b0774090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe6b0774090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe7d650f590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe6b0774090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphSAGEAggregator.call of <stellargraph.layer.graphsage.MeanAggregator object at 0x7fe6b0774090>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LinkEmbedding.call of <stellargraph.layer.link_inference.LinkEmbedding object at 0x7fe7c3b68810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method LinkEmbedding.call of <stellargraph.layer.link_inference.LinkEmbedding object at 0x7fe7c3b68810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7209 - binary_accuracy: 0.5000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:32.236388: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step - loss: 0.7082 - binary_accuracy: 0.5000\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:32.909371: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 662ms/step - loss: 0.6881 - binary_accuracy: 0.5095\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:33.592032: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 804ms/step - loss: 0.6588 - binary_accuracy: 0.5619\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:34.261190: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.6469 - binary_accuracy: 0.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:34.973129: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 268ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 01:19:35.542598: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "\r",
      " 75%|███████████████████████████████████████████████████████████████████████████████████████████▌                              | 9/12 [00:31<00:14,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe6a01915d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe6a01915d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe6a0185050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe6a0185050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe6a0185f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe6a0185f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe6a02f8e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe6a02f8e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - val_loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0086 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 10/12 [00:42<00:13,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe65af6f750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method SqueezedSparseConversion.call of <stellargraph.layer.misc.SqueezedSparseConversion object at 0x7fe65af6f750>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe65afb3bd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe65afb3bd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe65af682d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GraphAttentionSparse.call of <stellargraph.layer.graph_attention.GraphAttentionSparse object at 0x7fe65af682d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe65afb3b50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <bound method GatherIndices.call of <stellargraph.layer.misc.GatherIndices object at 0x7fe65afb3b50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 11/12 [00:57<00:09,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosswalk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:59<00:00,  4.99s/it]\n"
     ]
    }
   ],
   "source": [
    "embs = {}\n",
    "\n",
    "for k, model in tqdm(models.items()):\n",
    "    print(model.__class__.__name__)\n",
    "#     sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    if \"unbiased\" in k:\n",
    "        from residual2vec.word2vec import Word2Vec\n",
    "        m = Word2Vec(vocab_size=A.shape[0] + 1, embedding_size=dim, padding_idx=A.shape[0])\n",
    "        emb = model.fit(A).transform(m)\n",
    "    else:    \n",
    "        emb = model.fit(A).transform(dim=dim)\n",
    "#     sys.stdout = sys.__stdout__\n",
    "    embs[k] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_graph(emb, n, m):\n",
    "    # choose top m edges to reconstruct the graph\n",
    "    S = emb @ emb.T\n",
    "    S = np.triu(S, k=1)\n",
    "    r, c, v = sparse.find(S)\n",
    "    idx = np.argsort(-v)[:m]\n",
    "    r, c, v = r[idx], c[idx], v[idx]\n",
    "    B = sparse.csr_matrix((v, (r, c)), shape=(n, n))\n",
    "    B = B + B.T\n",
    "    B.data = B.data * 0 + 1\n",
    "    return nx.from_scipy_sparse_matrix(B + B.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_edges = int(A.sum() / 2)\n",
    "n_nodes = A.shape[0]\n",
    "rgraphs = {}\n",
    "for k, emb in embs.items():\n",
    "    rgraphs[k] = reconstruct_graph(emb, n_nodes, n_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class score:  baseline 0.18350637969381656\n",
      "class score:  degree-unbiased 0.16521661092407866\n",
      "class score:  group-unbiased 0.09946197228769423\n",
      "class score:  fairwalk 0.14611477419158628\n",
      "class score:  fairwalk-group 0.15413466652344265\n",
      "class score:  GCN 0.1749531430181661\n",
      "class score:  gcn-doubleK 0.15307040457197071\n",
      "class score:  graphsage 0.11287101092527081\n",
      "class score:  graphsage-doubleK 0.08316304422887198\n",
      "class score:  gat 0.17252836971977867\n",
      "class score:  gat-doubleK 0.15063600711097294\n",
      "class score:  crosswalk 0.08914961058135262\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for k, graph in rgraphs.items():\n",
    "    scores[k] = statistical_parity(graph, group_ids)\n",
    "    print(\"class score: \", k, scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0,'baseline'),\n",
       " Text(0,0,'degree-unbiased'),\n",
       " Text(0,0,'group-unbiased'),\n",
       " Text(0,0,'fairwalk'),\n",
       " Text(0,0,'fairwalk-group'),\n",
       " Text(0,0,'GCN'),\n",
       " Text(0,0,'gcn-doubleK'),\n",
       " Text(0,0,'graphsage'),\n",
       " Text(0,0,'graphsage-doubleK'),\n",
       " Text(0,0,'gat'),\n",
       " Text(0,0,'gat-doubleK'),\n",
       " Text(0,0,'crosswalk')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "ax = sns.barplot(x=list(scores.keys()), y=list(scores.values()))\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(rgraphs, open('/tmp/rgraphs.pkl', 'wb'))\n",
    "pkl.dump(group_ids, open('/tmp/group_ids.pkl', 'wb'))\n",
    "pkl.dump(embs, open('/tmp/embs.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check shapes of different properties of the r2v\n",
    "model = models['degree-unbiased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residual2vec.residual2vec_sgd.residual2vec_sgd"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 128), (105, 128))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.in_vec.shape, model.out_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}