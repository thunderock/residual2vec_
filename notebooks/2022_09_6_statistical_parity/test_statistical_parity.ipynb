{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook \n",
    "\n",
    "Implementing and testing the statistical parity with the political blog network. \n",
    "\n",
    "Source:\n",
    "- [Fairwalk paper](https://www.ijcai.org/proceedings/2019/456)\n",
    "\n",
    "## Statistical parity \n",
    "\n",
    "Statistical parity is a variance of the probability of edges at group level. The key idea is the following. Let's group nodes based on given node labels. If the presence of edges are independent of the given node labels, the probability of edges within and between the groups are the uniform. More specifically, suppose a network with edges recommended by a system. Assuming that the network is symmetric, \n",
    "the probability of the recommended edges between group $k$ and group $\\ell$, denoted by Let $P_{k\\ell}$, is given by \n",
    "$$\n",
    "\\begin{align}\n",
    "P_{k\\ell} = \\left\\{ \\begin{array}{cc} \n",
    "\\frac{1}{N_{k}(N_{k} - 1)/2} \\sum_{i \\in N_k}\\sum_{j \\in N_k, i<j} A_{ij}& \\text{(if $k=\\ell$)}\\\\\n",
    "\\frac{1}{N_{k}N_{\\ell}} \\sum_{i \\in N_k}\\sum_{i \\in N_\\ell}A_{ij} & \\text{(otherwise)}\\\\\n",
    "\\end{array} \\right.\n",
    "\\end{align}\n",
    "$$\n",
    "where $A_{ij} = 1$ if nodes $i$ and $j$ are connected, otherwise $A_{ij}=0$. \n",
    "The denominator $N_k(N_{k} - 1)/2$ is the total number of unique node pairs that belong to group $k$, excluding the self-loops, e.g., $(1, 1)$, $(2,2), \\ldots, (N_k, N_k)$.  \n",
    "Then, the statistical parity is given by the variance of the probabilities:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(P_{k \\ell}) = \\frac{1}{K(K+1)/2}\\sum_{k=1}^K \\sum_{\\ell=k}^K P_{k\\ell}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "While the definition of the statistical parity in the fairwalk paper is variance, the original definition of the statistical parity is the *standard deviation*. I believe that this is an error. The correct formula for the statistical parity is the following:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sqrt{\\text{Var}(P_{k \\ell})} = \\sqrt{\\frac{1}{K(K+1)/2}\\sum_{k=1}^K \\sum_{\\ell=k}^K P_{k\\ell}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "def statistical_parity(edges, y):\n",
    "    \"\"\"\n",
    "    edges: edge df with source and target column\n",
    "    y: original labels\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = len(y) # number of nodes\n",
    "    n_edges = edges.shape[0] # number of nodes\n",
    "    uy, y = np.unique(y, return_inverse=True) # to ensure that the labels are continuous integers starting from zero \n",
    "    K = len(uy) # number of classes\n",
    "\n",
    "    # We need two groups at least\n",
    "    assert K >= 2\n",
    "\n",
    "    # Group membership matrix, where U[i,k] = 1 if node $i$ belongs to group $k$ \n",
    "    U = sparse.csr_matrix((np.ones_like(y), (np.arange(n_nodes), y)), shape=(n_nodes, K))\n",
    "\n",
    "    # Number of nodes in each group\n",
    "    Nk = np.array(U.sum(axis = 0)).reshape(-1) \n",
    "\n",
    "    # Adjacency matrix\n",
    "    A = sparse.csr_matrix((np.ones(n_edges), (edges[\"source\"].values, edges[\"target\"].values)), shape=(n_nodes, n_nodes))\n",
    "\n",
    "    # Make sure that the adjacency matrix is symemtric \n",
    "    A = A + A.T\n",
    "    A.data = A.data *0 + 1\n",
    "\n",
    "    # Calculate the number of edges that appear in each group \n",
    "    M = U.T @ A @ U\n",
    "\n",
    "    # Calculate the edge density\n",
    "    Mdenom = np.outer(Nk, Nk) - np.diag(Nk) \n",
    "    P = M / Mdenom\n",
    "    # Calculate the statistical parity \n",
    "    parity = np.std(P[np.triu_indices(K)])\n",
    "    return parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "In the following test, I calculate the statistical parity for the original network. As a baseline, I calculate the statistical parity for shuffled labels, which should have a smaller statistical parity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical parity: original labels= 0.0663, random labels = 0.0185\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    " \n",
    "G = nx.read_gml(\"../../data/polbooks.gml\")\n",
    "labels = [d[1][\"value\"] for d in G.nodes(data = True)]\n",
    "\n",
    "source, target, _ = sparse.find(nx.adjacency_matrix(G))\n",
    "edges = pd.DataFrame({\"source\":source, \"target\":target})\n",
    "\n",
    "random_labels = np.random.choice(len(set(labels)), len(labels), replace=True)\n",
    "\n",
    "score = statistical_parity(edges, labels)\n",
    "score_random = statistical_parity(edges, random_labels) \n",
    "print(f\"Statistical parity: original labels= {score:.4f}, random labels = {score_random:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('authordynamics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ba3cc8ac23911f9837f125f410aa79985736e9a53ede8675efb0dd78c13842c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
