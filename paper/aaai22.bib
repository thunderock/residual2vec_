@article{DBLP:journals/corr/abs-1102-2166,
  author    = {Amanda L. Traud and
               Peter J. Mucha and
               Mason A. Porter},
  title     = {Social Structure of Facebook Networks},
  journal   = {CoRR},
  volume    = {abs/1102.2166},
  year      = {2011},
  url       = {http://arxiv.org/abs/1102.2166},
  eprinttype = {arXiv},
  eprint    = {1102.2166},
  timestamp = {Mon, 13 Aug 2018 16:48:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1102-2166.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{rozemberczki2021twitch,
      title={Twitch Gamers: a Dataset for Evaluating Proximity Preserving and Structural Role-based Node Embeddings}, 
      author={Benedek Rozemberczki and Rik Sarkar},
      year={2021},
      eprint={2101.03091},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
}
@article{Mirhoseini2021AGP,
  title={A graph placement methodology for fast chip design},
  author={Azalia Mirhoseini and Anna Goldie and Mustafa Yazgan and Joe Wenjie Jiang and Ebrahim M. Songhori and Shen Wang and Young-Joon Lee and Eric Johnson and Omkar Pathak and Azade Nazi and Jiwoo Pak and Andy Tong and Kavya Srinivasa and Will Hang and Emre Tuncer and Quoc V. Le and James Laudon and Richard Ho and Roger Carpenter and Jeff Dean},
  journal={Nature},
  year={2021},
  volume={594 7862},
  pages={
          207-212
        }
}
@article{DBLP:journals/corr/abs-2108-11482,
  author    = {Austin Derrow{-}Pinion and
               Jennifer She and
               David Wong and
               Oliver Lange and
               Todd Hester and
               Luis Perez and
               Marc Nunkesser and
               Seongjae Lee and
               Xueying Guo and
               Brett Wiltshire and
               Peter W. Battaglia and
               Vishal Gupta and
               Ang Li and
               Zhongwen Xu and
               Alvaro Sanchez{-}Gonzalez and
               Yujia Li and
               Petar Velickovic},
  title     = {{ETA} Prediction with Graph Neural Networks in Google Maps},
  journal   = {CoRR},
  volume    = {abs/2108.11482},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.11482},
  eprinttype = {arXiv},
  eprint    = {2108.11482},
  timestamp = {Fri, 13 May 2022 22:45:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-11482.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Jumper2021HighlyAP,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={John M. Jumper and Richard Evans and Alexander Pritzel and Tim Green and Michael Figurnov and Olaf Ronneberger and Kathryn Tunyasuvunakool and Russ Bates and Augustin Z{\'i}dek and Anna Potapenko and Alex Bridgland and Clemens Meyer and Simon A A Kohl and Andy Ballard and Andrew Cowie and Bernardino Romera-Paredes and Stanislav Nikolov and Rishub Jain and Jonas Adler and Trevor Back and Stig Petersen and David A. Reiman and Ellen Clancy and Michal Zielinski and Martin Steinegger and Michalina Pacholska and Tamas Berghammer and Sebastian Bodenstein and David Silver and Oriol Vinyals and Andrew W. Senior and Koray Kavukcuoglu and Pushmeet Kohli and Demis Hassabis},
  journal={Nature},
  year={2021},
  volume={596},
  pages={583 - 589}
}
@inproceedings{10.1145/3442188.3445922,
author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ��},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445922},
doi = {10.1145/3442188.3445922},
abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {610–623},
numpages = {14},
location = {Virtual Event, Canada},
series = {FAccT '21}
}
@misc{OpenFlig19:online,
author = {},
title = {OpenFlights: Airport and airline data},
howpublished = {\url{https://openflights.org/data.html}},
month = {},
year = {},
note = {(Accessed on 01/12/2023)}
}

@inproceedings{10.1145/1134271.1134277,
author = {Adamic, Lada A. and Glance, Natalie},
title = {The Political Blogosphere and the 2004 U.S. Election: Divided They Blog},
year = {2005},
isbn = {1595932151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134271.1134277},
doi = {10.1145/1134271.1134277},
abstract = {In this paper, we study the linking patterns and discussion topics of political bloggers. Our aim is to measure the degree of interaction between liberal and conservative blogs, and to uncover any differences in the structure of the two communities. Specifically, we analyze the posts of 40 "A-list" blogs over the period of two months preceding the U.S. Presidential Election of 2004, to study how often they referred to one another and to quantify the overlap in the topics they discussed, both within the liberal and conservative communities, and also across communities. We also study a single day snapshot of over 1,000 political blogs. This snapshot captures blogrolls (the list of links to other blogs frequently found in sidebars), and presents a more static picture of a broader blogosphere. Most significantly, we find differences in the behavior of liberal and conservative blogs, with conservative blogs linking to each other more frequently and in a denser pattern.},
booktitle = {Proceedings of the 3rd International Workshop on Link Discovery},
pages = {36–43},
numpages = {8},
keywords = {social networks, link analysis, political blogs},
location = {Chicago, Illinois},
series = {LinkKDD '05}
}
@article{article,
author = {Takac, L. and Zábovský, Michal},
year = {2012},
month = {01},
pages = {1-6},
title = {Data analysis in public social networks},
journal = {International Scientific Conference and International Workshop Present Day Trends of Innovations}
}
@article{propublicamachinebias,
	Author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
	Day = 23,
	Journal = {ProPublica},
	Month = may,
	Title = {Machine bias},
	Url = {https://perma.cc/L4M4-TJQT},
	Year = {2016},
	Bdsk-Url-1 = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing}}
@article{persona2vec,
  title    = {Persona2vec: a flexible multi-role representations learning framework for graphs},
  author   = {Yoon, Jisung and Yang, Kai-Cheng and Jung, Woo-Sung and Ahn, Yong-Yeol},
  year     = 2021,
  month    = mar,
  keywords = {Graph embedding, Overlapping community, Social context, Social network analysis, Link prediction},
  abstract = {
              Graph embedding techniques, which learn low-dimensional representations of a graph, are achieving state-of-the-art performance in many graph mining tasks. Most existing embedding algorithms assign a single vector to each node, implicitly assuming that a single representation is enough to capture all characteristics of the node. However, across many domains, it is common to observe pervasively overlapping community structure, where most nodes belong to multiple communities, playing different roles depending on the contexts. Here, we propose \texttt{persona2vec}, a graph embedding framework that efficiently learns multiple representations of nodes based on their structural contexts. Using link prediction-based evaluation, we show that our framework is significantly faster than the existing state-of-the-art model while achieving better performance.
              },
  volume   = 7,
  pages    = {e439},
  journal  = {PeerJ Computer Science},
  issn     = {2376-5992},
  url      = {https://doi.org/10.7717/peerj-cs.439},
  doi      = {10.7717/peerj-cs.439}
}

@article{mengAnalysisNode2vecRandom2020,
  title    = {Analysis of node2vec random walks on networks},
  volume   = {476},
  url      = {https://royalsocietypublishing.org/doi/full/10.1098/rspa.2020.0447},
  doi      = {10.1098/rspa.2020.0447},
  abstract = {Random walks have been proven to be useful for constructing various algorithms to gain information on networks. Algorithm node2vec employs biased random walks to realize embeddings of nodes into low-dimensional spaces, which can then be used for tasks such as multi-label classification and link prediction. The performance of the node2vec algorithm in these applications is considered to depend on properties of random walks that the algorithm uses. In the present study, we theoretically and numerically analyse random walks used by the node2vec. Those random walks are second-order Markov chains. We exploit the mapping of its transition rule to a transition probability matrix among directed edges to analyse the stationary probability, relaxation times in terms of the spectral gap of the transition probability matrix, and coalescence time. In particular, we show that node2vec random walk accelerates diffusion when walkers are designed to avoid both backtracking and visiting a neighbour of the previously visited node but do not avoid them completely.},
  number   = {2243},
  urldate  = {2022-08-31},
  journal  = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  author   = {Meng, Lingqi and Masuda, Naoki},
  month    = nov,
  year     = {2020},
  note     = {Publisher: Royal Society},
  pages    = {20200447},
  file     = {Meng&Masuda-2020-Proceedings_of_the_Royal_Society_A_Mathematical,_Physical_and_Engineering_Sciences-Analysis_of_node2vec_random_walks_on_networks.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Meng&Masuda-2020-Proceedings_of_the_Royal_Society_A_Mathematical,_Physical_and_Engineering_Sciences-Analysis_of_node2vec_random_walks_on_networks.pdf:application/pdf}
}
@article{DBLP:journals/corr/abs-1903-03862,
  author    = {Hila Gonen and
               Yoav Goldberg},
  title     = {Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases
               in Word Embeddings But do not Remove Them},
  journal   = {CoRR},
  volume    = {abs/1903.03862},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.03862},
  eprinttype = {arXiv},
  eprint    = {1903.03862},
  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-03862.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/BolukbasiCZSK16a,
  author    = {Tolga Bolukbasi and
               Kai{-}Wei Chang and
               James Y. Zou and
               Venkatesh Saligrama and
               Adam Kalai},
  title     = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing
               Word Embeddings},
  journal   = {CoRR},
  volume    = {abs/1607.06520},
  year      = {2016},
  url       = {http://arxiv.org/abs/1607.06520},
  eprinttype = {arXiv},
  eprint    = {1607.06520},
  timestamp = {Mon, 13 Aug 2018 16:46:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BolukbasiCZSK16a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{vonluxburgTutorialSpectralClustering2007,
  title    = {A tutorial on spectral clustering},
  volume   = {17},
  issn     = {1573-1375},
  url      = {https://doi.org/10.1007/s11222-007-9033-z},
  doi      = {10.1007/s11222-007-9033-z},
  abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
  language = {en},
  number   = {4},
  urldate  = {2022-08-22},
  journal  = {Statistics and Computing},
  author   = {von Luxburg, Ulrike},
  month    = dec,
  year     = {2007},
  pages    = {395--416},
  file     = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/3ZGUSVGE/von Luxburg - 2007 - A tutorial on spectral clustering.pdf:application/pdf}
}

@misc{peixotoGraphtoolPythonLibrary2017,
  title     = {The graph-tool python library},
  copyright = {Creative Commons Attribution 4.0 International},
  url       = {https://figshare.com/articles/dataset/graph_tool/1164194},
  abstract  = {Graph-tool is an efficient Python module for manipulation and statistical analysis of graphs (a.k.a. networks). Contrary to most other python modules with similar functionality, the core data structures and algorithms are implemented in C++, making extensive use of template metaprogramming, based heavily on the Boost Graph Library. This confers it a level of performance that is comparable (both in memory usage and computation time) to that of a pure C/C++ library.},
  urldate   = {2022-08-18},
  publisher = {figshare},
  author    = {Peixoto, Tiago P.},
  year      = {2017},
  doi       = {10.6084/M9.FIGSHARE.1164194},
  note      = {Artwork Size: 136152697 Bytes
               Pages: 136152697 Bytes
               Type: dataset}
}
@misc{https://doi.org/10.48550/arxiv.1710.10903,
  doi       = {10.48550/ARXIV.1710.10903},
  url       = {https://arxiv.org/abs/1710.10903},
  author    = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Attention Networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1609.02907,
  doi       = {10.48550/ARXIV.1609.02907},
  url       = {https://arxiv.org/abs/1609.02907},
  author    = {Kipf, Thomas N. and Welling, Max},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{rosvallMapsRandomWalks2008,
  title   = {Maps of random walks on complex networks reveal community structure},
  volume  = {105},
  url     = {https://www.pnas.org/doi/10.1073/pnas.0706851105},
  doi     = {10.1073/pnas.0706851105},
  number  = {4},
  urldate = {2022-08-18},
  journal = {Proceedings of the National Academy of Sciences},
  author  = {Rosvall, Martin and Bergstrom, Carl T.},
  month   = jan,
  year    = {2008},
  note    = {Publisher: Proceedings of the National Academy of Sciences},
  pages   = {1118--1123},
  file    = {Rosvall&Bergstrom-2008-Proceedings_of_the_National_Academy_of_Sciences-Maps_of_random_walks_on_complex_networks_reveal_community_structure.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Rosvall&Bergstrom-2008-Proceedings_of_the_National_Academy_of_Sciences-Maps_of_random_walks_on_complex_networks_reveal_community_structure.pdf:application/pdf}
}

@misc{MapsRandomWalks,
  title   = {Maps of random walks on complex networks reveal community structure {\textbar} {PNAS}},
  url     = {https://www.pnas.org/doi/10.1073/pnas.0706851105},
  urldate = {2022-08-18}
}

@article{lancichinettiBenchmarkGraphsTesting2008,
  title    = {Benchmark graphs for testing community detection algorithms},
  volume   = {78},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.78.046110},
  doi      = {10.1103/PhysRevE.78.046110},
  abstract = {Community structure is one of the most important features of real networks and reveals the internal organization of the nodes. Many algorithms have been proposed but the crucial issue of testing, i.e., the question of how good an algorithm is, with respect to others, is still open. Standard tests include the analysis of simple artificial graphs with a built-in community structure, that the algorithm has to recover. However, the special graphs adopted in actual tests have a structure that does not reflect the real properties of nodes and communities found in real networks. Here we introduce a class of benchmark graphs, that account for the heterogeneity in the distributions of node degrees and of community sizes. We use this benchmark to test two popular methods of community detection, modularity optimization, and Potts model clustering. The results show that the benchmark poses a much more severe test to algorithms than standard benchmarks, revealing limits that may not be apparent at a first analysis.},
  number   = {4},
  urldate  = {2022-08-18},
  journal  = {Physical Review E},
  author   = {Lancichinetti, Andrea and Fortunato, Santo and Radicchi, Filippo},
  month    = oct,
  year     = {2008},
  note     = {Publisher: American Physical Society},
  pages    = {046110},
  file     = {Lancichinetti_et_al-2008-Physical_Review_E-Benchmark_graphs_for_testing_community_detection_algorithms.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Lancichinetti_et_al-2008-Physical_Review_E-Benchmark_graphs_for_testing_community_detection_algorithms.pdf:application/pdf}
}

@article{tandonCommunityDetectionNetworks2021,
  title    = {Community detection in networks using graph embeddings},
  volume   = {103},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.103.022316},
  doi      = {10.1103/PhysRevE.103.022316},
  abstract = {Graph embedding methods are becoming increasingly popular in the machine learning community, where they are widely used for tasks such as node classification and link prediction. Embedding graphs in geometric spaces should aid the identification of network communities as well because nodes in the same community should be projected close to each other in the geometric space, where they can be detected via standard data clustering algorithms. In this paper, we test the ability of several graph embedding techniques to detect communities on benchmark graphs. We compare their performance against that of traditional community detection algorithms. We find that the performance is comparable, if the parameters of the embedding techniques are suitably chosen. However, the optimal parameter set varies with the specific features of the benchmark graphs, like their size, whereas popular community detection algorithms do not require any parameter. So, it is not possible to indicate beforehand good parameter sets for the analysis of real networks. This finding, along with the high computational cost of embedding a network and grouping the points, suggests that, for community detection, current embedding techniques do not represent an improvement over network clustering algorithms.},
  number   = {2},
  urldate  = {2022-08-18},
  journal  = {Physical Review E},
  author   = {Tandon, Aditya and Albeshri, Aiiad and Thayananthan, Vijey and Alhalabi, Wadee and Radicchi, Filippo and Fortunato, Santo},
  month    = feb,
  year     = {2021},
  note     = {Publisher: American Physical Society},
  pages    = {022316},
  file     = {Tandon_et_al-2021-Physical_Review_E-Community_detection_in_networks_using_graph_embeddings.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Tandon_et_al-2021-Physical_Review_E-Community_detection_in_networks_using_graph_embeddings.pdf:application/pdf}
}

@article{gatesElementcentricClusteringComparison2019,
  title     = {Element-centric clustering comparison unifies overlaps and hierarchy},
  volume    = {9},
  copyright = {2019 The Author(s)},
  issn      = {2045-2322},
  url       = {https://www.nature.com/articles/s41598-019-44892-y},
  doi       = {10.1038/s41598-019-44892-y},
  abstract  = {Clustering is one of the most universal approaches for understanding complex data. A pivotal aspect of clustering analysis is quantitatively comparing clusterings; clustering comparison is the basis for many tasks such as clustering evaluation, consensus clustering, and tracking the temporal evolution of clusters. In particular, the extrinsic evaluation of clustering methods requires comparing the uncovered clusterings to planted clusterings or known metadata. Yet, as we demonstrate, existing clustering comparison measures have critical biases which undermine their usefulness, and no measure accommodates both overlapping and hierarchical clusterings. Here we unify the comparison of disjoint, overlapping, and hierarchically structured clusterings by proposing a new element-centric framework: elements are compared based on the relationships induced by the cluster structure, as opposed to the traditional cluster-centric philosophy. We demonstrate that, in contrast to standard clustering similarity measures, our framework does not suffer from critical biases and naturally provides unique insights into how the clusterings differ. We illustrate the strengths of our framework by revealing new insights into the organization of clusters in two applications: the improved classification of schizophrenia based on the overlapping and hierarchical community structure of fMRI brain networks, and the disentanglement of various social homophily factors in Facebook social networks. The universality of clustering suggests far-reaching impact of our framework throughout all areas of science.},
  language  = {en},
  number    = {1},
  urldate   = {2022-08-18},
  journal   = {Scientific Reports},
  author    = {Gates, Alexander J. and Wood, Ian B. and Hetrick, William P. and Ahn, Yong-Yeol},
  month     = jun,
  year      = {2019},
  note      = {Number: 1
               Publisher: Nature Publishing Group},
  pages     = {8574},
  file      = {Gates_et_al-2019-Scientific_Reports-Element-centric_clustering_comparison_unifies_overlaps_and_hierarchy.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Gates_et_al-2019-Scientific_Reports-Element-centric_clustering_comparison_unifies_overlaps_and_hierarchy.pdf:application/pdf}
}

@misc{benaych-georgesSpectralRadiiSparse2021,
  title     = {Spectral radii of sparse random matrices},
  url       = {http://arxiv.org/abs/1704.02945},
  doi       = {10.48550/arXiv.1704.02945},
  abstract  = {We establish bounds on the spectral radii for a large class of sparse random matrices, which includes the adjacency matrices of inhomogeneous Erd{\textbackslash}H\{o\}s-R{\textbackslash}'enyi graphs. Our error bounds are sharp for a large class of sparse random matrices. In particular, for the Erd{\textbackslash}H\{o\}s-R{\textbackslash}'enyi graph \$G(n,d/n)\$, our results imply that the smallest and second-largest eigenvalues of the adjacency matrix converge to the edges of the support of the asymptotic eigenvalue distribution provided that \$d {\textbackslash}gg {\textbackslash}log n\$. Together with the companion paper [3], where we analyse the extreme eigenvalues in the complementary regime \$d {\textbackslash}ll {\textbackslash}log n\$, this establishes a crossover in the behaviour of the extreme eigenvalues around \$d {\textbackslash}sim {\textbackslash}log n\$. Our results also apply to non-Hermitian sparse random matrices, corresponding to adjacency matrices of directed graphs. The proof combines (i) a new inequality between the spectral radius of a matrix and the spectral radius of its nonbacktracking version together with (ii) a new application of the method of moments for nonbacktracking matrices.},
  urldate   = {2022-08-16},
  publisher = {arXiv},
  author    = {Benaych-Georges, Florent and Bordenave, Charles and Knowles, Antti},
  month     = jan,
  year      = {2021},
  note      = {arXiv:1704.02945 [math]},
  file      = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/NEPPXAQK/Benaych-Georges et al. - 2021 - Spectral radii of sparse random matrices.pdf:application/pdf}
}

@article{decelleAsymptoticAnalysisStochastic2011,
  title    = {Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications},
  volume   = {84},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.84.066106},
  doi      = {10.1103/PhysRevE.84.066106},
  abstract = {In this paper we extend our previous work on the stochastic block model, a commonly used generative model for social and biological networks, and the problem of inferring functional groups or communities from the topology of the network. We use the cavity method of statistical physics to obtain an asymptotically exact analysis of the phase diagram. We describe in detail properties of the detectability-undetectability phase transition and the easy-hard phase transition for the community detection problem. Our analysis translates naturally into a belief propagation algorithm for inferring the group memberships of the nodes in an optimal way, i.e., that maximizes the overlap with the underlying group memberships, and learning the underlying parameters of the block model. Finally, we apply the algorithm to two examples of real-world networks and discuss its performance.},
  number   = {6},
  urldate  = {2022-07-12},
  journal  = {Physical Review E},
  author   = {Decelle, Aurelien and Krzakala, Florent and Moore, Cristopher and Zdeborová, Lenka},
  month    = dec,
  year     = {2011},
  note     = {Publisher: American Physical Society},
  pages    = {066106},
  file     = {Submitted Version:/Users/skojaku-admin/Zotero/storage/4UZNT3HP/Decelle et al. - 2011 - Asymptotic analysis of the stochastic block model .pdf:application/pdf}
}

@article{chenUniversalPhaseTransition2015,
  title    = {Universal phase transition in community detectability under a stochastic block model},
  volume   = {91},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.91.032804},
  doi      = {10.1103/PhysRevE.91.032804},
  abstract = {We prove the existence of an asymptotic phase-transition threshold on community detectability for the spectral modularity method [M. E. J. Newman, Phys. Rev. E 74, 036104 (2006) and Proc. Natl. Acad. Sci. (USA) 103, 8577 (2006)] under a stochastic block model. The phase transition on community detectability occurs as the intercommunity edge connection probability p grows. This phase transition separates a subcritical regime of small p, where modularity-based community detection successfully identifies the communities, from a supercritical regime of large p where successful community detection is impossible. We show that, as the community sizes become large, the asymptotic phase-transition threshold p∗ is equal to √p1p2, where pi(i=1,2) is the within-community edge connection probability. Thus the phase-transition threshold is universal in the sense that it does not depend on the ratio of community sizes. The universal phase-transition phenomenon is validated by simulations for moderately sized communities. Using the derived expression for the phase-transition threshold, we propose an empirical method for estimating this threshold from real-world data.},
  number   = {3},
  urldate  = {2022-07-12},
  journal  = {Physical Review E},
  author   = {Chen, Pin-Yu and Hero, Alfred O.},
  month    = mar,
  year     = {2015},
  note     = {Publisher: American Physical Society},
  pages    = {032804},
  file     = {Accepted Version:/Users/skojaku-admin/Zotero/storage/MBQDTFCC/Chen and Hero - 2015 - Universal phase transition in community detectabil.pdf:application/pdf}
}

@article{chenPhaseTransitionsSpectral2015,
  title    = {Phase {Transitions} in {Spectral} {Community} {Detection}},
  volume   = {63},
  issn     = {1941-0476},
  url      = {https://ieeexplore.ieee.org/document/7120167},
  doi      = {10.1109/TSP.2015.2442958},
  abstract = {Consider a network consisting of two subnetworks (communities) connected by some external edges. Given the network topology, the community detection problem can be cast as a graph partitioning problem that aims to identify the external edges as the graph cut that separates these two subnetworks. In this paper, we consider a general model where two arbitrarily connected subnetworks are connected by random external edges. Using random matrix theory and concentration inequalities, we show that when one performs community detection via spectral clustering there exists an abrupt phase transition as a function of the random external edge connection probability. Specifically, the community detection performance transitions from almost perfect detectability to low detectability near some critical value of the random external edge connection probability. We derive upper and lower bounds on the critical value and show that the bounds are equal to each other when two subnetwork sizes are identical. Using simulated and experimental data we show how these bounds can be empirically estimated to validate the detection reliability of any discovered communities.},
  number   = {16},
  journal  = {IEEE Transactions on Signal Processing},
  author   = {Chen, Pin-Yu and Hero, Alfred O.},
  month    = aug,
  year     = {2015},
  note     = {Conference Name: IEEE Transactions on Signal Processing},
  pages    = {4339--4347},
  file     = {Submitted Version:/Users/skojaku-admin/Zotero/storage/KEESP2DZ/Chen and Hero - 2015 - Phase Transitions in Spectral Community Detection.pdf:application/pdf}
}

@inproceedings{kawamotoMeanfieldTheoryGraph2018,
  title     = {Mean-field theory of graph neural networks in graph partitioning},
  volume    = {31},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/f6e794a75c5d51de081dbefa224304f9-Abstract.html},
  abstract  = {A theoretical performance analysis of the graph neural network (GNN) is presented. For classification tasks, the neural network approach has the advantage in terms of flexibility that it can be employed in a data-driven manner, whereas Bayesian inference requires the assumption of a specific model. A fundamental question is then whether GNN has a high accuracy in addition to this flexibility. Moreover, whether the achieved performance is predominately a result of the backpropagation or the architecture itself is a matter of considerable interest. To gain a better insight into these questions, a mean-field theory of a minimal GNN architecture is developed for the graph partitioning problem. This demonstrates a good agreement with numerical experiments.},
  urldate   = {2022-07-08},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Kawamoto, Tatsuro and Tsubaki, Masashi and Obuchi, Tomoyuki},
  year      = {2018},
  file      = {Kawamoto_et_al-2018-Advances_in_Neural_Information_Processing_Systems-Mean-field_theory_of_graph_neural_networks_in_graph_partitioning.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Kawamoto_et_al-2018-Advances_in_Neural_Information_Processing_Systems-Mean-field_theory_of_graph_neural_networks_in_graph_partitioning.pdf:application/pdf}
}

@article{kawamotoAlgorithmicDetectabilityThreshold2018,
  title    = {Algorithmic detectability threshold of the stochastic block model},
  volume   = {97},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.97.032301},
  doi      = {10.1103/PhysRevE.97.032301},
  abstract = {The assumption that the values of model parameters are known or correctly learned, i.e., the Nishimori condition, is one of the requirements for the detectability analysis of the stochastic block model in statistical inference. In practice, however, there is no example demonstrating that we can know the model parameters beforehand, and there is no guarantee that the model parameters can be learned accurately. In this study, we consider the expectation–maximization (EM) algorithm with belief propagation (BP) and derive its algorithmic detectability threshold. Our analysis is not restricted to the community structure but includes general modular structures. Because the algorithm cannot always learn the planted model parameters correctly, the algorithmic detectability threshold is qualitatively different from the one with the Nishimori condition.},
  number   = {3},
  urldate  = {2022-07-07},
  journal  = {Physical Review E},
  author   = {Kawamoto, Tatsuro},
  month    = mar,
  year     = {2018},
  note     = {Publisher: American Physical Society},
  pages    = {032301},
  file     = {Submitted Version:/Users/skojaku-admin/Zotero/storage/DQ7EJ68X/Kawamoto - 2018 - Algorithmic detectability threshold of the stochas.pdf:application/pdf}
}

@article{radicchiParadoxCommunityDetection2014,
  title    = {A paradox in community detection},
  volume   = {106},
  issn     = {0295-5075},
  url      = {https://doi.org/10.1209/0295-5075/106/38001},
  doi      = {10.1209/0295-5075/106/38001},
  abstract = {Recent research has shown that virtually all algorithms aimed at the identification of communities in networks are affected by the same main limitation: the impossibility to detect communities, even when these are well defined, if the average value of the difference between internal and external node degrees does not exceed a strictly positive value, in the literature known as detectability threshold. Here, we counterintuitively show that the value of this threshold is inversely proportional to the intrinsic quality of communities: the detection of well-defined modules is thus more difficult than the identification of ill-defined communities.},
  language = {en},
  number   = {3},
  urldate  = {2022-07-06},
  journal  = {EPL (Europhysics Letters)},
  author   = {Radicchi, Filippo},
  month    = may,
  year     = {2014},
  note     = {Publisher: IOP Publishing},
  pages    = {38001},
  file     = {Submitted Version:/Users/skojaku-admin/Zotero/storage/CJ9ASXPM/Radicchi - 2014 - A paradox in community detection.pdf:application/pdf}
}

@inproceedings{aroraImplicitRegularizationDeep2019,
  title     = {Implicit {Regularization} in {Deep} {Matrix} {Factorization}},
  volume    = {32},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/c0c783b5fc0d7d808f1d14a6e9c8280d-Abstract.html},
  abstract  = {Efforts to understand the generalization mystery in deep learning have led to the belief that gradient-based optimization induces a form of implicit regularization, a bias towards models of low "complexity."  We study the implicit regularization of gradient descent over deep linear neural networks for matrix completion and sensing, a model referred to as deep matrix factorization.  Our first finding, supported by theory and experiments, is that adding depth to a matrix factorization enhances an implicit tendency towards low-rank solutions, oftentimes leading to more accurate recovery.  Secondly, we present theoretical and empirical arguments questioning a nascent view by which implicit regularization in matrix factorization can be captured using simple mathematical norms.  Our results point to the possibility that the language of standard regularizers may not be rich enough to fully encompass the implicit regularization brought forth by gradient-based optimization.},
  urldate   = {2022-07-02},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  year      = {2019},
  file      = {Arora_et_al-2019-Advances_in_Neural_Information_Processing_Systems-Implicit_Regularization_in_Deep_Matrix_Factorization.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Arora_et_al-2019-Advances_in_Neural_Information_Processing_Systems-Implicit_Regularization_in_Deep_Matrix_Factorization.pdf:application/pdf}
}

@article{delvenneStabilityGraphCommunities2010,
  title   = {Stability of graph communities across time scales},
  volume  = {107},
  url     = {https://www.pnas.org/doi/10.1073/pnas.0903215107},
  doi     = {10.1073/pnas.0903215107},
  number  = {29},
  urldate = {2022-07-01},
  journal = {Proceedings of the National Academy of Sciences},
  author  = {Delvenne, J.-C. and Yaliraki, S. N. and Barahona, M.},
  month   = jul,
  year    = {2010},
  note    = {Publisher: Proceedings of the National Academy of Sciences},
  pages   = {12755--12760},
  file    = {Delvenne_et_al-2010-Proceedings_of_the_National_Academy_of_Sciences-Stability_of_graph_communities_across_time_scales.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Delvenne_et_al-2010-Proceedings_of_the_National_Academy_of_Sciences-Stability_of_graph_communities_across_time_scales.pdf:application/pdf}
}

@inproceedings{mikolovDistributedRepresentationsWords2013,
  title     = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
  volume    = {26},
  url       = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
  abstract  = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. "},
  urldate   = {2022-06-30},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  year      = {2013},
  file      = {Mikolov_et_al-2013-Advances_in_Neural_Information_Processing_Systems-Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Mikolov_et_al-2013-Advances_in_Neural_Information_Processing_Systems-Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality.pdf:application/pdf}
}

@inproceedings{qiuNetworkEmbeddingMatrix2018,
  address    = {New York, NY, USA},
  series     = {{WSDM} '18},
  title      = {Network {Embedding} as {Matrix} {Factorization}: {Unifying} {DeepWalk}, {LINE}, {PTE}, and node2vec},
  isbn       = {978-1-4503-5581-0},
  shorttitle = {Network {Embedding} as {Matrix} {Factorization}},
  url        = {https://doi.org/10.1145/3159652.3159706},
  doi        = {10.1145/3159652.3159706},
  abstract   = {Since the invention of word2vec, the skip-gram model has significantly advanced the research of network embedding, such as the recent emergence of the DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of the aforementioned models with negative sampling can be unified into the matrix factorization framework with closed forms. Our analysis and proofs reveal that: (1) DeepWalk empirically produces a low-rank transformation of a network's normalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk when the size of vertices' context is set to one; (3) As an extension of LINE, PTE can be viewed as the joint factorization of multiple networks» Laplacians; (4) node2vec is factorizing a matrix related to the stationary distribution and transition probability tensor of a 2nd-order random walk. We further provide the theoretical connections between skip-gram based network embedding algorithms and the theory of graph Laplacian. Finally, we present the NetMF method as well as its approximation algorithm for computing network embedding. Our method offers significant improvements over DeepWalk and LINE for conventional network mining tasks. This work lays the theoretical foundation for skip-gram based network embedding methods, leading to a better understanding of latent network representation learning.},
  urldate    = {2022-06-29},
  booktitle  = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
  publisher  = {Association for Computing Machinery},
  author     = {Qiu, Jiezhong and Dong, Yuxiao and Ma, Hao and Li, Jian and Wang, Kuansan and Tang, Jie},
  month      = feb,
  year       = {2018},
  keywords   = {graph embedding},
  pages      = {459--467},
  file       = {Submitted Version:/Users/skojaku-admin/Zotero/storage/HM4C6ZZF/Qiu et al. - 2018 - Network Embedding as Matrix Factorization Unifyin.pdf:application/pdf}
}

@inproceedings{levyNeuralWordEmbedding2014,
  title     = {Neural {Word} {Embedding} as {Implicit} {Matrix} {Factorization}},
  volume    = {27},
  url       = {https://papers.nips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html},
  abstract  = {We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization.},
  urldate   = {2022-06-30},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Levy, Omer and Goldberg, Yoav},
  year      = {2014},
  keywords  = {graph embedding},
  file      = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/Z5N4UHN8/Levy and Goldberg - 2014 - Neural Word Embedding as Implicit Matrix Factoriza.pdf:application/pdf}
}

@inproceedings{penningtonGloVeGlobalVectors2014,
  address    = {Doha, Qatar},
  title      = {{GloVe}: {Global} {Vectors} for {Word} {Representation}},
  shorttitle = {{GloVe}},
  url        = {https://aclanthology.org/D14-1162},
  doi        = {10.3115/v1/D14-1162},
  urldate    = {2022-06-30},
  booktitle  = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
  publisher  = {Association for Computational Linguistics},
  author     = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  month      = oct,
  year       = {2014},
  keywords   = {graph embedding},
  pages      = {1532--1543},
  file       = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/TGUEJ39E/Pennington et al. - 2014 - GloVe Global Vectors for Word Representation.pdf:application/pdf}
}

@inproceedings{groverNode2vecScalableFeature2016,
  address    = {New York, NY, USA},
  series     = {{KDD} '16},
  title      = {node2vec: {Scalable} {Feature} {Learning} for {Networks}},
  isbn       = {978-1-4503-4232-2},
  shorttitle = {node2vec},
  url        = {https://doi.org/10.1145/2939672.2939754},
  doi        = {10.1145/2939672.2939754},
  abstract   = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
  urldate    = {2022-06-29},
  booktitle  = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
  publisher  = {Association for Computing Machinery},
  author     = {Grover, Aditya and Leskovec, Jure},
  month      = aug,
  year       = {2016},
  keywords   = {graph embedding, detectability limit},
  pages      = {855--864},
  file       = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/H8BYE5FW/Grover and Leskovec - 2016 - node2vec Scalable Feature Learning for Networks.pdf:application/pdf}
}

@inproceedings{perozziDeepWalkOnlineLearning2014,
  address    = {New York, NY, USA},
  series     = {{KDD} '14},
  title      = {{DeepWalk}: online learning of social representations},
  isbn       = {978-1-4503-2956-9},
  shorttitle = {{DeepWalk}},
  url        = {https://doi.org/10.1145/2623330.2623732},
  doi        = {10.1145/2623330.2623732},
  abstract   = {We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10\% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60\% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.},
  urldate    = {2022-06-29},
  booktitle  = {Proceedings of the 20th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
  publisher  = {Association for Computing Machinery},
  author     = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
  month      = aug,
  year       = {2014},
  keywords   = {graph embedding, detectability limit},
  pages      = {701--710},
  file       = {Submitted Version:/Users/skojaku-admin/Zotero/storage/D4X5NZRI/Perozzi et al. - 2014 - DeepWalk online learning of social representation.pdf:application/pdf}
}
@article{Edwards2015CensoringRW,
  title={Censoring Representations with an Adversary},
  author={Harrison Edwards and Amos J. Storkey},
  journal={CoRR},
  year={2015},
  volume={abs/1511.05897}
}
@article{belkinLaplacianEigenmapsDimensionality2003,
  title    = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
  volume   = {15},
  issn     = {0899-7667},
  doi      = {10.1162/089976603321780317},
  abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
  number   = {6},
  journal  = {Neural Computation},
  author   = {Belkin, Mikhail and Niyogi, Partha},
  month    = jun,
  year     = {2003},
  note     = {Conference Name: Neural Computation},
  keywords = {detectability limit},
  pages    = {1373--1396},
  file     = {Submitted Version:/Users/skojaku-admin/Zotero/storage/UJTQHBZ7/Belkin and Niyogi - 2003 - Laplacian Eigenmaps for Dimensionality Reduction a.pdf:application/pdf}
}

@article{coifmanDiffusionMaps2006,
  series   = {Special {Issue}: {Diffusion} {Maps} and {Wavelets}},
  title    = {Diffusion maps},
  volume   = {21},
  issn     = {1063-5203},
  url      = {https://www.sciencedirect.com/science/article/pii/S1063520306000546},
  doi      = {10.1016/j.acha.2006.04.006},
  abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
  language = {en},
  number   = {1},
  urldate  = {2022-06-30},
  journal  = {Applied and Computational Harmonic Analysis},
  author   = {Coifman, Ronald R. and Lafon, Stéphane},
  month    = jul,
  year     = {2006},
  keywords = {detectability limit},
  pages    = {5--30},
  file     = {Full Text:/Users/skojaku-admin/Zotero/storage/G9QSNTFV/Coifman and Lafon - 2006 - Diffusion maps.pdf:application/pdf}
}

@inproceedings{kunegisLearningSpectralGraph2009,
  address   = {New York, NY, USA},
  series    = {{ICML} '09},
  title     = {Learning spectral graph transformations for link prediction},
  isbn      = {978-1-60558-516-1},
  url       = {https://doi.org/10.1145/1553374.1553447},
  doi       = {10.1145/1553374.1553447},
  abstract  = {We present a unified framework for learning link prediction and edge weight prediction functions in large networks, based on the transformation of a graph's algebraic spectrum. Our approach generalizes several graph kernels and dimensionality reduction methods and provides a method to estimate their parameters efficiently. We show how the parameters of these prediction functions can be learned by reducing the problem to a one-dimensional regression problem whose runtime only depends on the method's reduced rank and that can be inspected visually. We derive variants that apply to undirected, weighted, unweighted, unipartite and bipartite graphs. We evaluate our method experimentally using examples from social networks, collaborative filtering, trust networks, citation networks, authorship graphs and hyperlink networks.},
  urldate   = {2022-06-27},
  booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
  publisher = {Association for Computing Machinery},
  author    = {Kunegis, Jérôme and Lommatzsch, Andreas},
  month     = jun,
  year      = {2009},
  keywords  = {embedding},
  pages     = {561--568},
  file      = {Kunegis&Lommatzsch-2009-Proceedings_of_the_26th_Annual_International_Conference_on_Machine_Learning-Learning_spectral_graph_transformations_for_link_prediction.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Kunegis&Lommatzsch-2009-Proceedings_of_the_26th_Annual_International_Conference_on_Machine_Learning-Learning_spectral_graph_transformations_for_link_prediction.pdf:application/pdf}
}

@inproceedings{tangLINELargescaleInformation2015,
  address    = {Republic and Canton of Geneva, CHE},
  series     = {{WWW} '15},
  title      = {{LINE}: {Large}-scale {Information} {Network} {Embedding}},
  isbn       = {978-1-4503-3469-3},
  shorttitle = {{LINE}},
  url        = {https://doi.org/10.1145/2736277.2741093},
  doi        = {10.1145/2736277.2741093},
  abstract   = {This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online{\textbackslash}footnote\{{\textbackslash}url\{https://github.com/tangjianpku/LINE\}\}.},
  urldate    = {2022-06-24},
  booktitle  = {Proceedings of the 24th {International} {Conference} on {World} {Wide} {Web}},
  publisher  = {International World Wide Web Conferences Steering Committee},
  author     = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
  month      = may,
  year       = {2015},
  pages      = {1067--1077},
  file       = {Tang_et_al-2015-Proceedings_of_the_24th_International_Conference_on_World_Wide_Web-LINE.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Tang_et_al-2015-Proceedings_of_the_24th_International_Conference_on_World_Wide_Web-LINE.pdf:application/pdf}
}

@book{koshyCatalanNumbersApplications2008,
  address   = {New York},
  title     = {Catalan {Numbers} with {Applications}},
  isbn      = {978-0-19-533454-8},
  url       = {https://oxford.universitypressscholarship.com/10.1093/acprof:oso/9780195334548.001.0001/acprof-9780195334548},
  abstract  = {Fibonacci and Lucas sequences are “two shining stars in the vast array of integer sequences,” and because of their ubiquitousness, tendency to appear in quite unexpected and unrelated places, abundant applications, and intriguing properties, they have fascinated amateurs and mathematicians alike. However, Catalan numbers are even more fascinating. Like the North Star in the evening sky, they are a beautiful and bright light in the mathematical heavens. They continue to provide a fertile ground for number theorists, especially, Catalan enthusiasts and computer scientists. Since the publication of Euler's triangulation problem (1751) and Catalan's parenthesization problem (1838), over 400 articles and problems on Catalan numbers have appeared in various periodicals. As Martin Gardner noted, even though many amateurs and mathematicians may know the abc's of Catalan sequence, they may not be familiar with their myriad unexpected occurrences, delightful applications, properties, or the beautiful and surprising relationships among numerous examples. Like Fibonacci and Lucas numbers, Catalan numbers are also an excellent source of fun and excitement. They can be used to generate interesting dividends for students, such as intellectual curiosity, experimentation, pattern recognition, conjecturing, and problem-solving techniques. The central character in the nth Catalan number is the central binomial coefficient. So, Catalan numbers can be extracted from Pascal's triangle. In fact, there are a number of ways they can be read from Pascal's triangle; every one of them is described and exemplified. This brings Catalan numbers a step closer to number-theory enthusiasts, especially.},
  language  = {eng},
  urldate   = {2022-06-24},
  publisher = {Oxford University Press},
  author    = {Koshy, Thomas},
  year      = {2008},
  doi       = {10.1093/acprof:oso/9780195334548.001.0001}
}

@misc{zhangConsistencyRandomwalkBased2021,
  title     = {Consistency of random-walk based network embedding algorithms},
  url       = {http://arxiv.org/abs/2101.07354},
  doi       = {10.48550/arXiv.2101.07354},
  abstract  = {Random-walk based network embedding algorithms like node2vec and DeepWalk are widely used to obtain Euclidean representation of the nodes in a network prior to performing down-stream network inference tasks. Nevertheless, despite their impressive empirical performance, there is a lack of theoretical results explaining their behavior. In this paper we studied the node2vec and DeepWalk algorithms through the perspective of matrix factorization. We analyze these algorithms in the setting of community detection for stochastic blockmodel graphs; in particular we established large-sample error bounds and prove consistent community recovery of node2vec/DeepWalk embedding followed by k-means clustering. Our theoretical results indicate a subtle interplay between the sparsity of the observed networks, the window sizes of the random walks, and the convergence rates of the node2vec/DeepWalk embedding toward the embedding of the true but unknown edge probabilities matrix. More specifically, as the network becomes sparser, our results suggest using larger window sizes, or equivalently, taking longer random walks, in order to attain better convergence rate for the resulting embeddings. The paper includes numerical experiments corroborating these observations.},
  urldate   = {2022-06-23},
  publisher = {arXiv},
  author    = {Zhang, Yichi and Tang, Minh},
  month     = jan,
  year      = {2021},
  note      = {Number: arXiv:2101.07354
               arXiv:2101.07354 [cs, stat]},
  file      = {Zhang&Tang-2021-Consistency_of_random-walk_based_network_embedding_algorithms.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Zhang&Tang-2021-Consistency_of_random-walk_based_network_embedding_algorithms.pdf:application/pdf}
}

@article{krzakalaSpectralRedemptionClustering2013,
  title   = {Spectral redemption in clustering sparse networks},
  volume  = {110},
  url     = {https://www.pnas.org/doi/10.1073/pnas.1312486110},
  doi     = {10.1073/pnas.1312486110},
  number  = {52},
  urldate = {2022-06-23},
  journal = {Proceedings of the National Academy of Sciences},
  author  = {Krzakala, Florent and Moore, Cristopher and Mossel, Elchanan and Neeman, Joe and Sly, Allan and Zdeborová, Lenka and Zhang, Pan},
  month   = dec,
  year    = {2013},
  note    = {Publisher: Proceedings of the National Academy of Sciences},
  pages   = {20935--20940},
  file    = {Krzakala_et_al-2013-Proceedings_of_the_National_Academy_of_Sciences-Spectral_redemption_in_clustering_sparse_networks.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Krzakala_et_al-2013-Proceedings_of_the_National_Academy_of_Sciences-Spectral_redemption_in_clustering_sparse_networks.pdf:application/pdf}
}

@misc{barotCommunityDetectionUsing2021,
  title     = {Community detection using low-dimensional network embedding algorithms},
  url       = {http://arxiv.org/abs/2111.05267},
  doi       = {10.48550/arXiv.2111.05267},
  abstract  = {With the increasing relevance of large networks in important areas such as the study of contact networks for spread of disease, or social networks for their impact on geopolitics, it has become necessary to study machine learning tools that are scalable to very large networks, often containing millions of nodes. One major class of such scalable algorithms is known as network representation learning or network embedding. These algorithms try to learn representations of network functionals (e.g.{\textasciitilde}nodes) by first running multiple random walks and then using the number of co-occurrences of each pair of nodes in observed random walk segments to obtain a low-dimensional representation of nodes on some Euclidean space. The aim of this paper is to rigorously understand the performance of two major algorithms, DeepWalk and node2vec, in recovering communities for canonical network models with ground truth communities. Depending on the sparsity of the graph, we find the length of the random walk segments required such that the corresponding observed co-occurrence window is able to perform almost exact recovery of the underlying community assignments. We prove that, given some fixed co-occurrence window, node2vec using random walks with a low non-backtracking probability can succeed for much sparser networks compared to DeepWalk using simple random walks. Moreover, if the sparsity parameter is low, we provide evidence that these algorithms might not succeed in almost exact recovery. The analysis requires developing general tools for path counting on random networks having an underlying low-rank structure, which are of independent interest.},
  urldate   = {2022-06-23},
  publisher = {arXiv},
  author    = {Barot, Aman and Bhamidi, Shankar and Dhara, Souvik},
  month     = nov,
  year      = {2021},
  note      = {Number: arXiv:2111.05267
               arXiv:2111.05267 [cs, math, stat]},
  keywords  = {detectability limit},
  file      = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/UUGE2FUL/Barot et al. - 2021 - Community detection using low-dimensional network .pdf:application/pdf}
}

@article{youngFinitesizeAnalysisDetectability2017,
  title    = {Finite-size analysis of the detectability limit of the stochastic block model},
  volume   = {95},
  doi      = {10.1103/physreve.95.062304},
  abstract = {It has been shown in recent years that the stochastic block model (SBM) is sometimes undetectable in the sparse limit, i.e., that no algorithm can identify a partition correlated with the partition used to generate an instance, if the instance is sparse enough and infinitely large. In this contribution, we treat the finite case explicitly, using arguments drawn from information theory and statistics. We give a necessary condition for finite-size detectability in the general SBM. We then distinguish the concept of average detectability from the concept of instance-by-instance detectability and give explicit formulas for both definitions. Using these formulas, we prove that there exist large equivalence classes of parameters, where widely different network ensembles are equally detectable with respect to our definitions of detectability. In an extensive case study, we investigate the finite-size detectability of a simplified variant of the SBM, which encompasses a number of important models as special cases. These models include the symmetric SBM, the planted coloring model, and more exotic SBMs not previously studied. We conclude with three appendices, where we study the interplay of noise and detectability, establish a connection between our information-theoretic approach and random matrix theory, and provide proofs of some of the more technical results.},
  number   = {6},
  journal  = {Physical Review E},
  author   = {Young, Jean-Gabriel and Desrosiers, Patrick and Hébert-Dufresne, Laurent and Laurence, Edward and Dubé, Louis J.},
  month    = jun,
  year     = {2017},
  doi      = {10.1103/physreve.95.062304},
  note     = {MAG ID: 2569164302},
  keywords = {detectability limit},
  pages    = {062304}
}

@article{kawamotoLimitationsSpectralMethod2015,
  title    = {Limitations in the spectral method for graph partitioning: {Detectability} threshold and localization of eigenvectors.},
  volume   = {91},
  doi      = {10.1103/physreve.91.062803},
  abstract = {Investigating the performance of different methods is a fundamental problem in graph partitioning. In this paper, we estimate the so-called detectability threshold for the spectral method with both unnormalized and normalized Laplacians in sparse graphs. The detectability threshold is the critical point at which the result of the spectral method is completely uncorrelated to the planted partition. We also analyze whether the localization of eigenvectors affects the partitioning performance in the detectable region. We use the replica method, which is often used in the field of spin-glass theory, and focus on the case of bisection. We show that the gap between the estimated threshold for the spectral method and the threshold obtained from Bayesian inference is considerable in sparse graphs, even without eigenvector localization. This gap closes in a dense limit.},
  number   = {6},
  journal  = {Physical Review E},
  author   = {Kawamoto, Tatsuro and Kabashima, Yoshiyuki},
  month    = jun,
  year     = {2015},
  doi      = {10.1103/physreve.91.062803},
  pmid     = {26172750},
  note     = {MAG ID: 2162403210},
  keywords = {detectability limit},
  pages    = {062803}
}

@article{DBLP:journals/corr/HamiltonYL17,
  author    = {William L. Hamilton and
               Rex Ying and
               Jure Leskovec},
  title     = {Inductive Representation Learning on Large Graphs},
  journal   = {CoRR},
  volume    = {abs/1706.02216},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02216},
  eprinttype = {arXiv},
  eprint    = {1706.02216},
  timestamp = {Mon, 13 Aug 2018 16:46:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HamiltonYL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhangScalableDetectionStatistically2014,
  title    = {Scalable detection of statistically significant communities and hierarchies, using message passing for modularity},
  volume   = {111},
  doi      = {10.1073/pnas.1409770111},
  abstract = {Modularity is a popular measure of community structure. However, maximizing the modularity can lead to many competing partitions, with almost the same modularity, that are poorly correlated with each other. It can also produce illusory ‘‘communities’’ in random graphs where none exist. We address this problem by using the modularity as a Hamiltonian at finite temperature and using an efficient belief propagation algorithm to obtain the consensus of many partitions with high modularity, rather than looking for a single partition that maximizes it. We show analytically and numerically that the proposed algorithm works all of the way down to the detectability transition in networks generated by the stochastic block model. It also performs well on real-world networks, revealing large communities in some networks where previous work has claimed no communities exist. Finally we show that by applying our algorithm recursively, subdividing communities until no statistically significant subcommunities can be found, we can detect hierarchical structure in real-world networks more efficiently than previous methods.},
  number   = {51},
  journal  = {Proceedings of the National Academy of Sciences of the United States of America},
  author   = {Zhang, Pan and Moore, Cristopher},
  month    = dec,
  year     = {2014},
  doi      = {10.1073/pnas.1409770111},
  pmcid    = {4280643},
  pmid     = {25489096},
  note     = {MAG ID: 2156028561},
  keywords = {detectability limit},
  pages    = {18144--18149}
}

@article{peixotoParsimoniousModuleInference2013,
  title    = {Parsimonious module inference in large networks},
  volume   = {110},
  doi      = {10.1103/physrevlett.110.148701},
  abstract = {We investigate the detectability of modules in large networks when the number of modules is not known in advance. We employ the minimum description length principle which seeks to minimize the total amount of information required to describe the network, and avoid overfitting. According to this criterion, we obtain general bounds on the detectability of any prescribed block structure, given the number of nodes and edges in the sampled network. We also obtain that the maximum number of detectable blocks scales as √N, where N is the number of nodes in the network, for a fixed average degree ⟨k⟩. We also show that the simplicity of the minimum description length approach yields an efficient multilevel Monte Carlo inference algorithm with a complexity of O(τNlogN), if the number of blocks is unknown, and O(τN) if it is known, where τ is the mixing time of the Markov chain. We illustrate the application of the method on a large network of actors and films with over 106 edges, and a dissortative, bipartite block structure.},
  number   = {14},
  journal  = {Physical Review Letters},
  author   = {Peixoto, Tiago P.},
  month    = apr,
  year     = {2013},
  doi      = {10.1103/physrevlett.110.148701},
  pmid     = {25167049},
  note     = {MAG ID: 2038224551},
  keywords = {detectability limit},
  pages    = {148701}
}

@article{chenPhaseTransitionsSpectral2015a,
  title    = {Phase {Transitions} in {Spectral} {Community} {Detection} of {Large} {Noisy} {Networks}},
  abstract = {In this paper, we study the sensitivity of the spectral clustering based community detection algorithm subject to a Erdos-Renyi type random noise model. We prove phase transitions in community detectability as a function of the external edge connection probability and the noisy edge presence probability under a general network model where two arbitrarily connected communities are interconnected by random external edges. Specifically, the community detection performance transitions from almost perfect detectability to low detectability as the inter-community edge connection probability exceeds some critical value. We derive upper and lower bounds on the critical value and show that the bounds are identical when the two communities have the same size. The phase transition results are validated using network simulations. Using the derived expressions for the phase transition threshold we propose a method for estimating this threshold from observed data.},
  journal  = {arXiv: Social and Information Networks},
  author   = {Chen, Pin-Yu and Chen, Pin-Yu and Hero, Alfred O.},
  month    = apr,
  year     = {2015},
  note     = {MAG ID: 1517622252},
  keywords = {detectability limit}
}

@article{kawamotoDetectabilitySpectralMethod2015,
  title    = {Detectability of the spectral method for sparse graph partitioning},
  doi      = {10.1209/0295-5075/112/40007},
  abstract = {We show that modularity maximization with the resolution parameter offers a unifying framework of graph partitioning. In this framework, we demonstrate that the spectral method exhibits universal detectability, irrespective of the value of the resolution parameter, as long as the graph is partitioned. Furthermore, we show that when the resolution parameter is sufficiently small, a first-order phase transition occurs, resulting in the graph being unpartitioned.},
  journal  = {EPL},
  author   = {Kawamoto, Tatsuro and Kabashima, Yoshiyuki},
  month    = sep,
  year     = {2015},
  doi      = {10.1209/0295-5075/112/40007},
  note     = {MAG ID: 3105181037},
  keywords = {detectability limit}
}

@article{radicchiDecodingCommunitiesNetworks2018,
  title    = {Decoding communities in networks.},
  volume   = {97},
  doi      = {10.1103/physreve.97.022316},
  abstract = {According to a recent information-theoretical proposal, the problem of defining and identifying communities in networks can be interpreted as a classical communication task over a noisy channel: memberships of nodes are information bits erased by the channel, edges and non-edges in the network are parity bits introduced by the encoder but degraded through the channel, and a community identification algorithm is a decoder. The interpretation is perfectly equivalent to the one at the basis of well-known statistical inference algorithms for community detection. The only difference in the interpretation is that a noisy channel replaces a stochastic network model. However, the different perspective gives the opportunity to take advantage of the rich set of tools of coding theory to generate novel insights on the problem of community detection. In this paper, we illustrate two main applications of standard coding-theoretical methods to community detection. First, we leverage a state-of-the-art decoding technique to generate a family of quasi-optimal community detection algorithms. Second and more important, we show that the Shannon's noisy-channel coding theorem can be invoked to establish a lower bound, here named as decodability bound, for the maximum amount of noise tolerable by an ideal decoder to achieve perfect detection of communities. When computed for well-established synthetic benchmarks, the decodability bound explains accurately the performance achieved by the best community detection algorithms existing on the market, telling us that only little room for their improvement is still potentially left.},
  number   = {2},
  journal  = {Physical Review E},
  author   = {Radicchi, Filippo},
  month    = feb,
  year     = {2018},
  doi      = {10.1103/physreve.97.022316},
  pmid     = {29548249},
  note     = {MAG ID: 2770186095},
  keywords = {detectability limit},
  pages    = {022316}
}

@article{radicchiDetectabilityCommunitiesHeterogeneous2013,
  title    = {Detectability of communities in heterogeneous networks},
  volume   = {88},
  url      = {https://link.aps.org/doi/10.1103/PhysRevE.88.010801},
  doi      = {10.1103/PhysRevE.88.010801},
  abstract = {Communities are fundamental entities for the characterization of the structure of real networks. The standard approach to the identification of communities in networks is based on the optimization of a quality function known as modularity. Although modularity has been at the center of an intense research activity and many methods for its maximization have been proposed, not much is yet known about the necessary conditions that communities need to satisfy in order to be detectable with modularity maximization methods. Here, we develop a simple theory to establish these conditions, and we successfully apply it to various classes of network models. Our main result is that heterogeneity in the degree distribution helps modularity to correctly recover the community structure of a network and that, in the realistic case of scale-free networks with degree exponent γ{\textless}2.5, modularity is always able to detect the presence of communities.},
  number   = {1},
  urldate  = {2022-06-18},
  journal  = {Physical Review E},
  author   = {Radicchi, Filippo},
  month    = jul,
  year     = {2013},
  note     = {Publisher: American Physical Society},
  keywords = {detectability limit},
  pages    = {010801},
  file     = {Radicchi-2013-Physical_Review_E-Detectability_of_communities_in_heterogeneous_networks.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Radicchi-2013-Physical_Review_E-Detectability_of_communities_in_heterogeneous_networks.pdf:application/pdf}
}

@article{nadakuditiGraphSpectraDetectability2012,
  title    = {Graph {Spectra} and the {Detectability} of {Community} {Structure} in {Networks}},
  volume   = {108},
  url      = {https://link.aps.org/doi/10.1103/PhysRevLett.108.188701},
  doi      = {10.1103/PhysRevLett.108.188701},
  abstract = {We study networks that display community structure—groups of nodes within which connections are unusually dense. Using methods from random matrix theory, we calculate the spectra of such networks in the limit of large size, and hence demonstrate the presence of a phase transition in matrix methods for community detection, such as the popular modularity maximization method. The transition separates a regime in which such methods successfully detect the community structure from one in which the structure is present but is not detected. By comparing these results with recent analyses of maximum-likelihood methods, we are able to show that spectral modularity maximization is an optimal detection method in the sense that no other method will succeed in the regime where the modularity method fails.},
  number   = {18},
  urldate  = {2022-06-13},
  journal  = {Physical Review Letters},
  author   = {Nadakuditi, Raj Rao and Newman, M. E. J.},
  month    = may,
  year     = {2012},
  note     = {Publisher: American Physical Society},
  keywords = {detectability limit},
  pages    = {188701},
  file     = {Nadakuditi&Newman-2012-Physical_Review_Letters-Graph_Spectra_and_the_Detectability_of_Community_Structure_in_Networks.pdf:/Users/skojaku-admin/Library/CloudStorage/GoogleDrive-skojaku@iu.edu/My Drive/Zotero/Nadakuditi&Newman-2012-Physical_Review_Letters-Graph_Spectra_and_the_Detectability_of_Community_Structure_in_Networks.pdf:application/pdf}
}


@misc{Dyer2014,
  doi       = {10.48550/ARXIV.1410.8251},
  url       = {https://arxiv.org/abs/1410.8251},
  author    = {Dyer, Chris},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Notes on Noise Contrastive Estimation and Negative Sampling},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{Gutmann2010,
  title     = {Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author    = {Gutmann, Michael and Hyvärinen, Aapo},
  booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages     = {297--304},
  year      = {2010},
  editor    = {Teh, Yee Whye and Titterington, Mike},
  volume    = {9},
  series    = {Proceedings of Machine Learning Research},
  address   = {Chia Laguna Resort, Sardinia, Italy},
  month     = {13--15 May},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf},
  url       = {https://proceedings.mlr.press/v9/gutmann10a.html}
}



@inproceedings{conf/icdm/KamiranKVG12,
  added-at = {2017-05-26T00:00:00.000+0200},
  author = {Kamiran, Faisal and Karim, Asim and Verwer, Sicco and Goudriaan, Heike},
  biburl = {https://www.bibsonomy.org/bibtex/2c98674a5f61078da8ac58e6e94d29018/dblp},
  booktitle = {ICDM Workshops},
  crossref = {conf/icdm/2012w},
  editor = {Vreeken, Jilles and Ling, Charles and Zaki, Mohammed Javeed and Siebes, Arno and Yu, Jeffrey Xu and Goethals, Bart and Webb, Geoffrey I. and Wu, Xindong},
  ee = {http://doi.ieeecomputersociety.org/10.1109/ICDMW.2012.117},
  interhash = {93dd57e80ba4ec4f054479f709d9167a},
  intrahash = {c98674a5f61078da8ac58e6e94d29018},
  isbn = {978-1-4673-5164-5},
  keywords = {dblp},
  pages = {370-377},
  publisher = {IEEE Computer Society},
  timestamp = {2019-10-17T13:01:37.000+0200},
  title = {Classifying Socially Sensitive Data Without Discrimination: An Analysis of a Crime Suspect Dataset.},
  url = {http://dblp.uni-trier.de/db/conf/icdm/icdmw2012.html#KamiranKVG12},
  year = 2012
}
@misc{https://doi.org/10.48550/arxiv.2208.00781,
  doi = {10.48550/ARXIV.2208.00781},
  
  url = {https://arxiv.org/abs/2208.00781},
  
  author = {Marcinkevičs, Ričards and Ozkan, Ece and Vogt, Julia E.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Debiasing Deep Chest X-Ray Classifiers using Intra- and Post-processing Methods},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{DBLP:journals/corr/abs-2107-10251,
  author    = {Dana Kenna},
  title     = {Using Adversarial Debiasing to Remove Bias from Word Embeddings},
  journal   = {CoRR},
  volume    = {abs/2107.10251},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.10251},
  eprinttype = {arXiv},
  eprint    = {2107.10251},
  timestamp = {Thu, 29 Jul 2021 16:14:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-10251.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/HardtPS16,
  author    = {Moritz Hardt and
               Eric Price and
               Nathan Srebro},
  title     = {Equality of Opportunity in Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/1610.02413},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.02413},
  eprinttype = {arXiv},
  eprint    = {1610.02413},
  timestamp = {Tue, 26 Apr 2022 09:17:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HardtPS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{kipf2017semisupervised,
  title         = {Semi-Supervised Classification with Graph Convolutional Networks},
  author        = {Thomas N. Kipf and Max Welling},
  year          = {2017},
  eprint        = {1609.02907},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}


@misc{grover_node2vec_2016,
  title      = {node2vec: {Scalable} {Feature} {Learning} for {Networks}},
  shorttitle = {node2vec},
  url        = {http://arxiv.org/abs/1607.00653},
  doi        = {10.48550/arXiv.1607.00653},
  abstract   = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
  urldate    = {2022-10-01},
  publisher  = {arXiv},
  author     = {Grover, Aditya and Leskovec, Jure},
  month      = jul,
  year       = {2016},
  note       = {arXiv:1607.00653 [cs, stat]},
  keywords   = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Social and Information Networks},
  annote     = {Comment: In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016},
  file       = {arXiv Fulltext PDF:/home/ashutosh/Zotero/storage/BLRLAUX7/Grover and Leskovec - 2016 - node2vec Scalable Feature Learning for Networks.pdf:application/pdf;arXiv.org Snapshot:/home/ashutosh/Zotero/storage/PLKINEMQ/1607.html:text/html}
}

@inproceedings{nr,
  title     = {The Network Data Repository with Interactive Graph Analytics and Visualization},
  author    = {Ryan A. Rossi and Nesreen K. Ahmed},
  booktitle = {AAAI},
  url       = {https://networkrepository.com},
  year      = {2015}
}
@inproceedings{10.1145/2090236.2090255,
author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
title = {Fairness through Awareness},
year = {2012},
isbn = {9781450311151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2090236.2090255},
doi = {10.1145/2090236.2090255},
abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
pages = {214–226},
numpages = {13},
location = {Cambridge, Massachusetts},
series = {ITCS '12}
}
@inproceedings{palowitchDebiasingGraphRepresentations2020,
	title = {Debiasing Graph Representations via Metadata-Orthogonal Training},
	doi = {10.1109/ASONAM49781.2020.9381348},
	abstract = {In real world graphs, the formation of edges can be associated with certain sensitive features of the nodes (e.g. gender, community, reputation). In this paper we argue that when such associations exist, any downstream Graph Neural Network ({GNN}) will be implicitly biased by these structural correlations. To allow control over this phenomenon, we introduce the Metadata-Orthogonal Node Embedding Training ({MONET}) unit, a general neural network module for performing training-time linear debiasing of graph embeddings. {MONET} operates by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node features (metadata). Unlike debiasing approaches in similar domains, our method offers exact guarantees about the correlation between the resulting embeddings and any sensitive metadata. We illustrate the effectiveness of {MONET} though our experiments on a variety of real world graphs against challenging baselines (e.g. adversarial debiasing), showing superior performance in tasks such as preventing the leakage of political party affiliation in a blog network, and preventing the gaming of embedding-based recommendation systems.},
	eventtitle = {2020 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	pages = {435--442},
	booktitle = {2020 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	author = {Palowitch, John and Perozzi, Bryan},
	date = {2020-12},
	note = {{ISSN}: 2473-991X},
	file = {IEEE Xplore Full Text PDF:/Users/skojaku-admin/Zotero/storage/WLTMQ2NX/Palowitch and Perozzi - 2020 - Debiasing Graph Representations via Metadata-Ortho.pdf:application/pdf},
}

@inproceedings{laclauAllFairnessEdge2021,
	title = {All of the Fairness for Edge Prediction with Optimal Transport},
	url = {https://proceedings.mlr.press/v130/laclau21a.html},
	abstract = {Machine learning and data mining algorithms have been increasingly used recently to support decision-making systems in many areas of high societal importance such as healthcare, education, or security. While being very efficient in their predictive abilities, the deployed algorithms sometimes tend to learn an inductive model with a discriminative bias due to the presence of this latter in the learning sample. This problem gave rise to a new field of algorithmic fairness where the goal is to correct the discriminative bias introduced by a certain attribute in order to decorrelate it from the model’s output. In this paper, we study the problem of fairness for the task of edge prediction in graphs, a largely underinvestigated scenario compared to a more popular setting of fair classification. To this end, we formulate the problem of fair edge prediction, analyze it theoretically, and propose an embedding-agnostic repairing procedure for the adjacency matrix of an arbitrary graph with a trade-off between the group and individual fairness. We experimentally show the versatility of our approach and its capacity to provide explicit control over different notions of fairness and prediction accuracy.},
	eventtitle = {International Conference on Artificial Intelligence and Statistics},
	pages = {1774--1782},
	booktitle = {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Laclau, Charlotte and Redko, Ievgen and Choudhary, Manvi and Largeron, Christine},
	urldate = {2022-07-26},
	date = {2021-03-18},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/Q8VJMCMP/Laclau et al. - 2021 - All of the Fairness for Edge Prediction with Optim.pdf:application/pdf;Supplementary PDF:/Users/skojaku-admin/Zotero/storage/8CW8YQ7E/Laclau et al. - 2021 - All of the Fairness for Edge Prediction with Optim.pdf:application/pdf},
}

@misc{khajehnejadCrossWalkFairnessenhancedNode2022,
	title = {{CrossWalk}: Fairness-enhanced Node Representation Learning},
	url = {http://arxiv.org/abs/2105.02725},
	doi = {10.48550/arXiv.2105.02725},
	shorttitle = {{CrossWalk}},
	abstract = {The potential for machine learning systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. Much recent work has focused on developing algorithmic tools to assess and mitigate such unfairness. However, there is little work on enhancing fairness in graph algorithms. Here, we develop a simple, effective and general method, {CrossWalk}, that enhances fairness of various graph algorithms, including influence maximization, link prediction and node classification, applied to node embeddings. {CrossWalk} is applicable to any random walk based node representation learning algorithm, such as {DeepWalk} and Node2Vec. The key idea is to bias random walks to cross group boundaries, by upweighting edges which (1) are closer to the groups' peripheries or (2) connect different groups in the network. {CrossWalk} pulls nodes that are near groups' peripheries towards their neighbors from other groups in the embedding space, while preserving the necessary structural properties of the graph. Extensive experiments show the effectiveness of our algorithm to enhance fairness in various graph algorithms, including influence maximization, link prediction and node classification in synthetic and real networks, with only a very small decrease in performance.},
	number = {{arXiv}:2105.02725},
	publisher = {{arXiv}},
	author = {Khajehnejad, Ahmad and Khajehnejad, Moein and Babaei, Mahmoudreza and Gummadi, Krishna P. and Weller, Adrian and Mirzasoleiman, Baharan},
	urldate = {2022-07-26},
	date = {2022-03-25},
	eprinttype = {arxiv},
	eprint = {2105.02725 [cs, stat]},
	file = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/ZQZKLH9T/Khajehnejad et al. - 2022 - CrossWalk Fairness-enhanced Node Representation L.pdf:application/pdf},
}

@misc{daiSayNoDiscrimination2021,
	title = {Say No to the Discrimination: Learning Fair Graph Neural Networks with Limited Sensitive Attribute Information},
	url = {http://arxiv.org/abs/2009.01454},
	shorttitle = {Say No to the Discrimination},
	abstract = {Graph neural networks ({GNNs}) have shown great power in modeling graph structured data. However, similar to other machine learning models, {GNNs} may make predictions biased on protected sensitive attributes, e.g., skin color and gender. Because machine learning algorithms including {GNNs} are trained to reflect the distribution of the training data which often contains historical bias towards sensitive attributes. In addition, the discrimination in {GNNs} can be magnified by graph structures and the message-passing mechanism. As a result, the applications of {GNNs} in sensitive domains such as crime rate prediction would be largely limited. Though extensive studies of fair classification have been conducted on i.i.d data, methods to address the problem of discrimination on non-i.i.d data are rather limited. Furthermore, the practical scenario of sparse annotations in sensitive attributes is rarely considered in existing works. Therefore, we study the novel and important problem of learning fair {GNNs} with limited sensitive attribute information. {FairGNN} is proposed to eliminate the bias of {GNNs} whilst maintaining high node classification accuracy by leveraging graph structures and limited sensitive information. Our theoretical analysis shows that {FairGNN} can ensure the fairness of {GNNs} under mild conditions given limited nodes with known sensitive attributes. Extensive experiments on real-world datasets also demonstrate the effectiveness of {FairGNN} in debiasing and keeping high accuracy.},
	number = {{arXiv}:2009.01454},
	publisher = {{arXiv}},
	author = {Dai, Enyan and Wang, Suhang},
	urldate = {2022-07-26},
	date = {2021-10-15},
	eprinttype = {arxiv},
	eprint = {2009.01454 [cs]},
	file = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/TZPGNJYD/Dai and Wang - 2021 - Say No to the Discrimination Learning Fair Graph .pdf:application/pdf},
}

@misc{chenBiasDebiasRecommender2021,
	title = {Bias and Debias in Recommender System: A Survey and Future Directions},
	url = {http://arxiv.org/abs/2010.03240},
	shorttitle = {Bias and Debias in Recommender System},
	abstract = {While recent years have witnessed a rapid growth of research papers on recommender system ({RS}), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in {RS}, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology ``bias'' is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on {RS} biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at {\textbackslash}url\{https://github.com/jiawei-chen/{RecDebiasing}\}.},
	number = {{arXiv}:2010.03240},
	publisher = {{arXiv}},
	author = {Chen, Jiawei and Dong, Hande and Wang, Xiang and Feng, Fuli and Wang, Meng and He, Xiangnan},
	urldate = {2022-07-26},
	date = {2021-12-29},
	eprinttype = {arxiv},
	eprint = {2010.03240 [cs]},
	keywords = {\_tablet\_modified},
	file = {Chen et al-2021-Bias and Debias in Recommender System.pdf:/Users/skojaku-admin/Zotero/storage/3TRMPS98/Chen et al-2021-Bias and Debias in Recommender System.pdf:application/pdf},
}

@inproceedings{buylKLDivergenceGraphModel2021,
	location = {Cham},
	title = {The {KL}-Divergence Between a Graph Model and its Fair I-Projection as a Fairness Regularizer},
	isbn = {978-3-030-86520-7},
	doi = {10.1007/978-3-030-86520-7_22},
	series = {Lecture Notes in Computer Science},
	abstract = {Learning and reasoning over graphs is increasingly done by means of probabilistic models, e.g. exponential random graph models, graph embedding models, and graph neural networks. When graphs are modeling relations between people, however, they will inevitably reflect biases, prejudices, and other forms of inequity and inequality. An important challenge is thus to design accurate graph modeling approaches while guaranteeing fairness according to the specific notion of fairness that the problem requires. Yet, past work on the topic remains scarce, is limited to debiasing specific graph modeling methods, and often aims to ensure fairness in an indirect manner.},
	pages = {351--366},
	booktitle = {Machine Learning and Knowledge Discovery in Databases. Research Track},
	publisher = {Springer International Publishing},
	author = {Buyl, Maarten and De Bie, Tijl},
	editor = {Oliver, Nuria and Pérez-Cruz, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
	date = {2021},
	langid = {english},
	file = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/T9NPUBGU/Buyl and De Bie - 2021 - The KL-Divergence Between a Graph Model and its Fa.pdf:application/pdf},
}

@inproceedings{buylDeBayesBayesianMethod2020,
	title = {{DeBayes}: a Bayesian Method for Debiasing Network Embeddings},
	url = {https://proceedings.mlr.press/v119/buyl20a.html},
	shorttitle = {{DeBayes}},
	abstract = {As machine learning algorithms are increasingly deployed for high-impact automated decision making, ethical and increasingly also legal standards demand that they treat all individuals fairly, without discrimination based on their age, gender, race or other sensitive traits. In recent years much progress has been made on ensuring fairness and reducing bias in standard machine learning settings. Yet, for network embedding, with applications in vulnerable domains ranging from social network analysis to recommender systems, current options remain limited both in number and performance. We thus propose {DeBayes}: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior. Our experiments show that these representations can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.},
	eventtitle = {International Conference on Machine Learning},
	pages = {1220--1229},
	booktitle = {Proceedings of the 37th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Buyl, Maarten and Bie, Tijl De},
	urldate = {2022-07-26},
	date = {2020-11-21},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/P84S6M3E/Buyl and Bie - 2020 - DeBayes a Bayesian Method for Debiasing Network E.pdf:application/pdf},
}

@inproceedings{bourliBiasKnowledgeGraph2020,
	title = {Bias in Knowledge Graph Embeddings},
	doi = {10.1109/ASONAM49781.2020.9381459},
	abstract = {In this paper, we study bias in knowledge graph embeddings. We focus on gender bias in occupations, but our approach is applicable to other types of bias. We start by proposing measures for identifying bias in the dataset (i.e., in the {KG}) and then present two methods for testing whether any bias in the dataset is amplified by the embeddings. First, we look for gender-specific occupation analogies in the embeddings. Second, we test whether link prediction (i.e., occupation prediction in our case) aggregates gender bias by proposing gender-dominated occupations to people of the corresponding gender more often than expected. Then, we use a debiasing approach based on projections on the gender subspace. We present experimental results using the Wikidata dataset and pretrained {TransE} embeddings. Our results show that there exists gender bias in the dataset and that such bias is amplified by the embeddings. Our debiasing approach removes bias with a small penalty on accuracy.},
	eventtitle = {2020 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	pages = {6--10},
	booktitle = {2020 {IEEE}/{ACM} International Conference on Advances in Social Networks Analysis and Mining ({ASONAM})},
	author = {Bourli, Styliani and Pitoura, Evaggelia},
	date = {2020-12},
	note = {{ISSN}: 2473-991X},
	file = {IEEE Xplore Full Text PDF:/Users/skojaku-admin/Zotero/storage/S8F42J8V/Bourli and Pitoura - 2020 - Bias in Knowledge Graph Embeddings.pdf:application/pdf},
}

@inproceedings{boseCompositionalFairnessConstraints2019,
	title = {Compositional Fairness Constraints for Graph Embeddings},
	url = {https://proceedings.mlr.press/v97/bose19a.html},
	abstract = {Learning high-quality node embeddings is a key building block for machine learning models that operate on graph data, such as social networks and recommender systems. However, existing graph embedding techniques are unable to cope with fairness constraints, e.g., ensuring that the learned representations do not correlate with certain attributes, such as age or gender. Here, we introduce an adversarial framework to enforce fairness constraints on graph embeddings. Our approach is compositional—meaning that it can flexibly accommodate different combinations of fairness constraints during inference. For instance, in the context of social recommendations, our framework would allow one user to request that their recommendations are invariant to both their age and gender, while also allowing another user to request invariance to just their age. Experiments on standard knowledge graph and recommender system benchmarks highlight the utility of our proposed framework.},
	eventtitle = {International Conference on Machine Learning},
	pages = {715--724},
	booktitle = {Proceedings of the 36th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Bose, Avishek and Hamilton, William},
	urldate = {2022-07-26},
	date = {2019-05-24},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/skojaku-admin/Zotero/storage/SXG5M64U/Bose and Hamilton - 2019 - Compositional Fairness Constraints for Graph Embed.pdf:application/pdf;Supplementary PDF:/Users/skojaku-admin/Zotero/storage/QY8Z8YEU/Bose and Hamilton - 2019 - Compositional Fairness Constraints for Graph Embed.pdf:application/pdf},
}

@misc{agarwalUnifiedFrameworkFair2021,
	title = {Towards a Unified Framework for Fair and Stable Graph Representation Learning},
	url = {http://arxiv.org/abs/2102.13186},
	doi = {10.48550/arXiv.2102.13186},
	abstract = {As the representations output by Graph Neural Networks ({GNNs}) are increasingly employed in real-world applications, it becomes important to ensure that these representations are fair and stable. In this work, we establish a key connection between counterfactual fairness and stability and leverage it to propose a novel framework, {NIFTY} ({uNIfying} Fairness and {stabiliTY}), which can be used with any {GNN} to learn fair and stable representations. We introduce a novel objective function that simultaneously accounts for fairness and stability and develop a layer-wise weight normalization using the Lipschitz constant to enhance neural message passing in {GNNs}. In doing so, we enforce fairness and stability both in the objective function as well as in the {GNN} architecture. Further, we show theoretically that our layer-wise weight normalization promotes counterfactual fairness and stability in the resulting representations. We introduce three new graph datasets comprising of high-stakes decisions in criminal justice and financial lending domains. Extensive experimentation with the above datasets demonstrates the efficacy of our framework.},
	number = {{arXiv}:2102.13186},
	publisher = {{arXiv}},
	author = {Agarwal, Chirag and Lakkaraju, Himabindu and Zitnik, Marinka},
	urldate = {2022-07-26},
	date = {2021-06-16},
	eprinttype = {arxiv},
	eprint = {2102.13186 [cs]},
	file = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/9I9EIVA7/Agarwal et al. - 2021 - Towards a Unified Framework for Fair and Stable Gr.pdf:application/pdf},
}

@article{spinelliFairDropBiasedEdge2022,
	title = {{FairDrop}: Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning},
	volume = {3},
	issn = {2691-4581},
	url = {http://arxiv.org/abs/2104.14210},
	doi = {10.1109/TAI.2021.3133818},
	shorttitle = {{FairDrop}},
	abstract = {Graph representation learning has become a ubiquitous component in many scenarios, ranging from social network analysis to energy forecasting in smart grids. In several applications, ensuring the fairness of the node (or graph) representations with respect to some protected attributes is crucial for their correct deployment. Yet, fairness in graph deep learning remains under-explored, with few solutions available. In particular, the tendency of similar nodes to cluster on several real-world graphs (i.e., homophily) can dramatically worsen the fairness of these procedures. In this paper, we propose a novel biased edge dropout algorithm ({FairDrop}) to counter-act homophily and improve fairness in graph representation learning. {FairDrop} can be plugged in easily on many existing algorithms, is efficient, adaptable, and can be combined with other fairness-inducing solutions. After describing the general algorithm, we demonstrate its application on two benchmark tasks, specifically, as a random walk model for producing node embeddings, and to a graph convolutional network for link prediction. We prove that the proposed algorithm can successfully improve the fairness of all models up to a small or negligible drop in accuracy, and compares favourably with existing state-of-the-art solutions. In an ablation study, we demonstrate that our algorithm can flexibly interpolate between biasing towards fairness and an unbiased edge dropout. Furthermore, to better evaluate the gains, we propose a new dyadic group definition to measure the bias of a link prediction task when paired with group-based fairness metrics. In particular, we extend the metric used to measure the bias in the node embeddings to take into account the graph structure.},
	pages = {344--354},
	number = {3},
	journaltitle = {{IEEE} Transactions on Artificial Intelligence},
	shortjournal = {{IEEE} Trans. Artif. Intell.},
	author = {Spinelli, Indro and Scardapane, Simone and Hussain, Amir and Uncini, Aurelio},
	urldate = {2022-07-26},
	date = {2022-06},
	eprinttype = {arxiv},
	eprint = {2104.14210 [cs, stat]},
	file = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/THN23IE2/Spinelli et al. - 2022 - FairDrop Biased Edge Dropout for Enhancing Fairne.pdf:application/pdf},
}

@misc{zengFairRepresentationLearning2021,
	title = {Fair Representation Learning for Heterogeneous Information Networks},
	url = {http://arxiv.org/abs/2104.08769},
	doi = {10.48550/arXiv.2104.08769},
	abstract = {Recently, much attention has been paid to the societal impact of {AI}, especially concerns regarding its fairness. A growing body of research has identified unfair {AI} systems and proposed methods to debias them, yet many challenges remain. Representation learning for Heterogeneous Information Networks ({HINs}), a fundamental building block used in complex network mining, has socially consequential applications such as automated career counseling, but there have been few attempts to ensure that it will not encode or amplify harmful biases, e.g. sexism in the job market. To address this gap, in this paper we propose a comprehensive set of de-biasing methods for fair {HINs} representation learning, including sampling-based, projection-based, and graph neural networks ({GNNs})-based techniques. We systematically study the behavior of these algorithms, especially their capability in balancing the trade-off between fairness and prediction accuracy. We evaluate the performance of the proposed methods in an automated career counseling application where we mitigate gender bias in career recommendation. Based on the evaluation results on two datasets, we identify the most effective fair {HINs} representation learning techniques under different conditions.},
	number = {{arXiv}:2104.08769},
	publisher = {{arXiv}},
	author = {Zeng, Ziqian and Islam, Rashidul and Keya, Kamrun Naher and Foulds, James and Song, Yangqiu and Pan, Shimei},
	urldate = {2022-07-26},
	date = {2021-04-18},
	eprinttype = {arxiv},
	eprint = {2104.08769 [cs]},
	file = {arXiv Fulltext PDF:/Users/skojaku-admin/Zotero/storage/UCEIZU92/Zeng et al. - 2021 - Fair Representation Learning for Heterogeneous Inf.pdf:application/pdf},
}

@article{doi:10.1080/0022250X.2012.744247,
author = { SONG   YANG },
title = {Networks: An Introduction by M. E. J. Newman},
journal = {The Journal of Mathematical Sociology},
volume = {37},
number = {4},
pages = {250-251},
year  = {2013},
publisher = {Routledge},
doi = {10.1080/0022250X.2012.744247},

URL = { 
    
        https://doi.org/10.1080/0022250X.2012.744247
    
    

},
eprint = { 
    
        https://doi.org/10.1080/0022250X.2012.744247
    
    

}

}

@article{rahmanFairwalkFairGraph2019,
	title = {Fairwalk: Towards Fair Graph Embedding},
	url = {https://www.ijcai.org/proceedings/2019/456},
	shorttitle = {Fairwalk},
	abstract = {Electronic proceedings of {IJCAI} 2019},
	pages = {3289--3295},
	author = {Rahman, Tahleen and Surma, Bartlomiej and Backes, Michael and Zhang, Yang},
	urldate = {2022-07-26},
	date = {2019},
	file = {Rahman et al. - 2019 - Fairwalk Towards Fair Graph Embedding.pdf:/Users/skojaku-admin/Zotero/storage/UPRMZ62Y/Rahman et al. - 2019 - Fairwalk Towards Fair Graph Embedding.pdf:application/pdf},
}

@inproceedings{tsioutsiouliklisFairnessAwarePageRank2021,
	location = {New York, {NY}, {USA}},
	title = {Fairness-Aware {PageRank}},
	isbn = {978-1-4503-8312-7},
	url = {https://doi.org/10.1145/3442381.3450065},
	doi = {10.1145/3442381.3450065},
	series = {{WWW} '21},
	abstract = {Algorithmic fairness has attracted significant attention in the past years. In this paper, we consider fairness for link analysis and in particular for the celebrated Pagerank algorithm. Given that the nodes in a network belong to groups (for example, based on demographic or other characteristics), we provide a parity-based definition of fairness that imposes constraints on the proportion of Pagerank allocated to the members of each group. We propose two families of fair Pagerank algorithms: the first (Fairness-Sensitive Pagerank) modifies the jump vector of the Pagerank algorithm to enforce fairness; the second (Locally Fair Pagerank) imposes a fair behavior per node. We then define a stronger fairness requirement, termed universal personalized fairness, that asks that the derived personalized pageranks of all nodes are fair. We prove that the locally fair algorithms achieve also universal personalized fairness, and furthermore, we prove that this is the only family of algorithms with this property, establishing an equivalence between universal personalized fairness and local fairness. We also consider the problem of achieving fairness while minimizing the utility loss with respect to the original Pagerank algorithm. We present experiments with real and synthetic networks that examine the fairness of the original Pagerank and demonstrate qualitatively and quantitatively the properties of our algorithms.},
	pages = {3815--3826},
	booktitle = {Proceedings of the Web Conference 2021},
	publisher = {Association for Computing Machinery},
	author = {Tsioutsiouliklis, Sotiris and Pitoura, Evaggelia and Tsaparas, Panayiotis and Kleftakis, Ilias and Mamoulis, Nikos},
	urldate = {2022-07-14},
	date = {2021-04-19},
}

@online{samuelNewAIDraws2022,
	title = {A new {AI} draws delightful and not-so-delightful images},
	url = {https://www.vox.com/future-perfect/23023538/ai-dalle-2-openai-bias-gpt-3-incentives},
	abstract = {{OpenAI}’s {DALL}-E 2 is incredible at turning text into images. It also highlights the problem of {AI} bias — and the need to change incentives in the industry.},
	titleaddon = {Vox},
	author = {Samuel, Sigal},
	urldate = {2023-01-03},
	date = {2022-04-14},
	langid = {english},
}

@online{GoogleFixesTranslate2018,
	title = {Google fixes Translate tool after accusations of sexism},
	url = {https://www.independent.co.uk/life-style/women/google-translate-sexist-masculine-feminine-he-said-she-said-english-spanish-languages-a8672586.html},
	abstract = {The tool was converting 'she said' to 'he said'},
	titleaddon = {The Independent},
	urldate = {2023-01-03},
	date = {2018-12-07},
	langid = {english},
	note = {Section: Lifestyle},
}

@online{pagesNikonCameraSays,
	title = {Nikon Camera Says Asians: People Are Always Blinking - Sociological Images},
	url = {https://thesocietypages.org/socimages/2009/05/29/nikon-camera-says-asians-are-always-blinking/},
	shorttitle = {Nikon Camera Says Asians},
	abstract = {The Society Pages ({TSP}) is an open-access social science project headquartered in the Department of Sociology at the University of Minnesota},
	author = {Pages, The Society},
	urldate = {2023-01-03},
	langid = {english},
}

@online{ResearchersShowThat2020,
	title = {Researchers show that computer vision algorithms pretrained on {ImageNet} exhibit multiple, distressing biases},
	url = {https://venturebeat.com/business/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/},
	abstract = {Researchers say they've found evidence of pervasive bias in computer vision algorithms trained on {ImageNet}, a popular photo dataset.},
	titleaddon = {{VentureBeat}},
	urldate = {2023-01-03},
	date = {2020-11-03},
	langid = {american},
}

@online{lashbrookAIDrivenDermatologyCould2018,
	title = {{AI}-Driven Dermatology Could Leave Dark-Skinned Patients Behind},
	url = {https://www.theatlantic.com/health/archive/2018/08/machine-learning-dermatology-skin-color/567619/},
	abstract = {Machine learning has the potential to save thousands of people from skin cancer each year—while putting others at greater risk.},
	titleaddon = {The Atlantic},
	author = {Lashbrook, Angela},
	urldate = {2023-01-03},
	date = {2018-08-16},
	langid = {english},
	note = {Section: Health},
}

@inreference{GenderBiasWikipedia2022,
	title = {Gender bias on Wikipedia},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Gender_bias_on_Wikipedia&oldid=1128262996},
	abstract = {Gender bias on Wikipedia, also known as the Wikipedia gender gap, refers to the fact that Wikipedia contributors are mostly male, that relatively few biographies on Wikipedia are about women, and that topics of interest to women are less well-covered.In a 2018 survey covering 12 language versions of Wikipedia and some other Wikimedia Foundation projects, 90\% of 3,734 respondents reported their gender as male, 8.8\% as female, and 1\% as other; among contributors to the English Wikipedia, 84.7\% identified as male, 13.6\% as female, and 1.7\% as other (total of 88 respondents). In 2019, Katherine Maher, then {CEO} of Wikimedia Foundation, said her team's working assumption was that women make up 15–20\% of total contributors.Wikipedia's articles about women are less likely to be included, expanded, neutral, and detailed. A 2021 study found that, in April 2017, 41\% of biographies nominated for deletion were women despite only 17\% of published biographies being women. The visibility and reachability of women on Wikipedia is limited, with a 2015 report finding that female pages generally "tend to be more linked to men". Language that is considered sexist, loaded, or otherwise gendered has been identified in articles about women. Gender bias features among the most frequent criticisms of Wikipedia, sometimes as part of a more general criticism about systemic bias in Wikipedia. 
In 2015, Wikipedia founder Jimmy Wales announced that the encyclopedia had failed to reach its goal to retain 25\% female editorship. Programs like edit-a-thons and Women in Red have been developed to encourage female editors and increase the coverage of women's topics. A study in 2020 found that progress has been made: The study investigated contributions from "central" versus "peripheral contributors" and that a balance between the two types of contributors results in the creation of content with the most neutral point of view.},
	booktitle = {Wikipedia},
	urldate = {2023-01-03},
	date = {2022-12-19},
	langid = {english},
	note = {Page Version {ID}: 1128262996},
}

@inproceedings{ravfogel-etal-2020-null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.647",
    doi = "10.18653/v1/2020.acl-main.647",
    pages = "7237--7256",
    abstract = "The ability to control for the kinds of information encoded in neural representation has a variety of use cases, especially in light of the challenge of interpreting these models. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space. By doing so, the classifiers become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.",
}

@inproceedings{zhao-etal-2018-gender,
    title = "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods",
    author = "Zhao, Jieyu  and
      Wang, Tianlu  and
      Yatskar, Mark  and
      Ordonez, Vicente  and
      Chang, Kai-Wei",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2003",
    doi = "10.18653/v1/N18-2003",
    pages = "15--20",
    abstract = "In this paper, we introduce a new benchmark for co-reference resolution focused on gender bias, WinoBias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets.",
}

